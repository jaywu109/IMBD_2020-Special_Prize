{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import MinMaxScaler, RobustScaler, StandardScaler\n",
    "from sklearn.linear_model import LinearRegression, LassoCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "import math\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from scipy import stats\n",
    "import matplotlib.style as style\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from scipy.stats import norm, skew #for some statistics\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "# 處理 data 套件\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from xgboost.sklearn import XGBRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score,KFold\n",
    "from scipy.stats import skew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def skew_pro(data):\n",
    "    columns=data.drop(['Predict'], axis=1).columns\n",
    "    for col in columns: \n",
    "        if abs(data[col].skew()) >= 0.7: \n",
    "            pt = PowerTransformer() \n",
    "            d = pt.fit_transform(data[col].values.reshape(-1, 1)).flatten()\n",
    "            data[col]=d\n",
    "    X = data[columns]\n",
    "    scaler = RobustScaler()\n",
    "    data[columns] = scaler.fit_transform(X)\n",
    "    \n",
    "    return data\n",
    "\n",
    "def lr_rmse_ave(x,y):\n",
    "    \n",
    "    \n",
    "    train_rmse=[]\n",
    "    test_rmse=[]\n",
    "    test_r2=[]\n",
    "    \n",
    "    for i in np.arange(10):\n",
    "        x_train,x_test,y_train,y_test = train_test_split(x,y, random_state = i)\n",
    "        lr = LinearRegression().fit(x_train,y_train)\n",
    "\n",
    "        y_train_pred = lr.predict(x_train)\n",
    "        y_test_pred = lr.predict(x_test)\n",
    "        train_rmse.append(mean_squared_error(y_train, y_train_pred,squared=False))\n",
    "        test_rmse.append(mean_squared_error(y_test, y_test_pred,squared=False))\n",
    "        test_r2.append(r2_score(y_test,y_test_pred))\n",
    "    \n",
    "    train_rmse=np.array(train_rmse).mean()\n",
    "    test_rmse=np.array(test_rmse).mean()\n",
    "    test_r2=np.array(test_r2).mean()\n",
    "    \n",
    "#     print('train_rmse:', train_rmse)\n",
    "#     print('test_rmse:', test_rmse)\n",
    "#     print('test_r2:', test_r2)\n",
    "    return train_rmse, test_rmse, test_r2\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input_A1_020\n",
      "./BayesianRidge_Pre_0/\n",
      "feature number: 2\n",
      "train_rmse: 0.5928217486273215\n",
      "test_rmse: 0.646585647097155\n",
      "test_r2: 0.370698679108309\n",
      "feature number: 3\n",
      "train_rmse: 0.5844720276614522\n",
      "test_rmse: 0.6511332225562532\n",
      "test_r2: 0.36485135531258117\n",
      "feature number: 4\n",
      "train_rmse: 0.5831209556536728\n",
      "test_rmse: 0.6568360159671985\n",
      "test_r2: 0.3545339642275792\n",
      "feature number: 5\n",
      "train_rmse: 0.5824025653306407\n",
      "test_rmse: 0.6594662460327358\n",
      "test_r2: 0.3493447817400817\n",
      "feature number: 6\n",
      "train_rmse: 0.5820069840234381\n",
      "test_rmse: 0.659608719896304\n",
      "test_r2: 0.34914455883802875\n",
      "feature number: 7\n",
      "train_rmse: 0.5817708592190032\n",
      "test_rmse: 0.6596553345534402\n",
      "test_r2: 0.3489464324693693\n",
      "feature number: 8\n",
      "train_rmse: 0.5807490080212043\n",
      "test_rmse: 0.6589953026259924\n",
      "test_r2: 0.3504795277327843\n",
      "feature number: 9\n",
      "train_rmse: 0.5740197085483204\n",
      "test_rmse: 0.6482825019788352\n",
      "test_r2: 0.3703332570152188\n",
      "feature number: 10\n",
      "train_rmse: 0.5683738583407798\n",
      "test_rmse: 0.6415633131733706\n",
      "test_r2: 0.38259426691083415\n",
      "feature number: 11\n",
      "train_rmse: 0.561757136157572\n",
      "test_rmse: 0.6378544790842416\n",
      "test_r2: 0.3897745418287683\n",
      "feature number: 12\n",
      "train_rmse: 0.5612153273697034\n",
      "test_rmse: 0.6385068407745663\n",
      "test_r2: 0.3883496127182242\n",
      "feature number: 13\n",
      "train_rmse: 0.5524479347779185\n",
      "test_rmse: 0.6330753174474051\n",
      "test_r2: 0.39702158399336024\n",
      "feature number: 14\n",
      "train_rmse: 0.5496703758835424\n",
      "test_rmse: 0.630685153741493\n",
      "test_r2: 0.4021163900449416\n",
      "feature number: 15\n",
      "train_rmse: 0.5485942028302637\n",
      "test_rmse: 0.6310994538907078\n",
      "test_r2: 0.40116194324817406\n",
      "feature number: 16\n",
      "train_rmse: 0.5481104288114287\n",
      "test_rmse: 0.6317231286074294\n",
      "test_r2: 0.399940063696876\n",
      "feature number: 17\n",
      "train_rmse: 0.54737558050624\n",
      "test_rmse: 0.6346503520847111\n",
      "test_r2: 0.39424085581656804\n",
      "feature number: 18\n",
      "train_rmse: 0.546374135068558\n",
      "test_rmse: 0.640957062501515\n",
      "test_r2: 0.3822139806527838\n",
      "feature number: 19\n",
      "train_rmse: 0.5460210501583901\n",
      "test_rmse: 0.6424231671700623\n",
      "test_r2: 0.379348210283628\n",
      "feature number: 20\n",
      "train_rmse: 0.5419897782021001\n",
      "test_rmse: 0.6448693714071021\n",
      "test_r2: 0.37396827703130825\n",
      "Test_rmse_min = 1.fea_num: 14  2.rmse: 0.630685153741493\n",
      "Test_r2_max = 1. fea_num: 14  2.r2: 0.4021163900449416\n",
      "./BayesianRidge_Pre_1/\n",
      "feature number: 2\n",
      "train_rmse: 0.5928217486273215\n",
      "test_rmse: 0.646585647097155\n",
      "test_r2: 0.370698679108309\n",
      "feature number: 3\n",
      "train_rmse: 0.5844720276614522\n",
      "test_rmse: 0.6511332225562532\n",
      "test_r2: 0.36485135531258117\n",
      "feature number: 4\n",
      "train_rmse: 0.5831209556536728\n",
      "test_rmse: 0.6568360159671985\n",
      "test_r2: 0.3545339642275792\n",
      "feature number: 5\n",
      "train_rmse: 0.5824025653306407\n",
      "test_rmse: 0.6594662460327358\n",
      "test_r2: 0.3493447817400817\n",
      "feature number: 6\n",
      "train_rmse: 0.5820069840234381\n",
      "test_rmse: 0.659608719896304\n",
      "test_r2: 0.34914455883802875\n",
      "feature number: 7\n",
      "train_rmse: 0.5817708592190032\n",
      "test_rmse: 0.6596553345534402\n",
      "test_r2: 0.3489464324693693\n",
      "feature number: 8\n",
      "train_rmse: 0.5807490080212043\n",
      "test_rmse: 0.6589953026259924\n",
      "test_r2: 0.3504795277327843\n",
      "feature number: 9\n",
      "train_rmse: 0.5740197085483204\n",
      "test_rmse: 0.6482825019788352\n",
      "test_r2: 0.3703332570152188\n",
      "feature number: 10\n",
      "train_rmse: 0.5683738583407798\n",
      "test_rmse: 0.6415633131733706\n",
      "test_r2: 0.38259426691083415\n",
      "feature number: 11\n",
      "train_rmse: 0.5616736178494212\n",
      "test_rmse: 0.6376899544959465\n",
      "test_r2: 0.39006834595013185\n",
      "feature number: 12\n",
      "train_rmse: 0.5611309008520509\n",
      "test_rmse: 0.6383397513366367\n",
      "test_r2: 0.3886497167117198\n",
      "feature number: 13\n",
      "train_rmse: 0.5524113687433625\n",
      "test_rmse: 0.6330708757358317\n",
      "test_r2: 0.3970168543221695\n",
      "feature number: 14\n",
      "train_rmse: 0.5496288432060938\n",
      "test_rmse: 0.6306910223906805\n",
      "test_r2: 0.4020894537802989\n",
      "feature number: 15\n",
      "train_rmse: 0.5484994001044723\n",
      "test_rmse: 0.6310821781419381\n",
      "test_r2: 0.4011643778375572\n",
      "feature number: 16\n",
      "train_rmse: 0.548028988558474\n",
      "test_rmse: 0.6316949670937927\n",
      "test_r2: 0.3999717912381093\n",
      "feature number: 17\n",
      "train_rmse: 0.5473140194332287\n",
      "test_rmse: 0.6346146438775138\n",
      "test_r2: 0.3943041980498435\n",
      "feature number: 18\n",
      "train_rmse: 0.5463121762886367\n",
      "test_rmse: 0.6409080938728028\n",
      "test_r2: 0.382300285895639\n",
      "feature number: 19\n",
      "train_rmse: 0.5459631044431589\n",
      "test_rmse: 0.6423523571059574\n",
      "test_r2: 0.3794677671949425\n",
      "feature number: 20\n",
      "train_rmse: 0.5420211395133248\n",
      "test_rmse: 0.6448996062532454\n",
      "test_r2: 0.37392367904457013\n",
      "Test_rmse_min = 1.fea_num: 14  2.rmse: 0.6306910223906805\n",
      "Test_r2_max = 1. fea_num: 14  2.r2: 0.4020894537802989\n",
      "./BayesianRidge_Pre_2/\n",
      "feature number: 2\n",
      "train_rmse: 0.5928217486273215\n",
      "test_rmse: 0.646585647097155\n",
      "test_r2: 0.370698679108309\n",
      "feature number: 3\n",
      "train_rmse: 0.5844720276614522\n",
      "test_rmse: 0.6511332225562532\n",
      "test_r2: 0.36485135531258117\n",
      "feature number: 4\n",
      "train_rmse: 0.5831209556536728\n",
      "test_rmse: 0.6568360159671985\n",
      "test_r2: 0.3545339642275792\n",
      "feature number: 5\n",
      "train_rmse: 0.5824025653306407\n",
      "test_rmse: 0.6594662460327358\n",
      "test_r2: 0.3493447817400817\n",
      "feature number: 6\n",
      "train_rmse: 0.5820069840234381\n",
      "test_rmse: 0.659608719896304\n",
      "test_r2: 0.34914455883802875\n",
      "feature number: 7\n",
      "train_rmse: 0.5817708592190032\n",
      "test_rmse: 0.6596553345534402\n",
      "test_r2: 0.3489464324693693\n",
      "feature number: 8\n",
      "train_rmse: 0.5807490080212043\n",
      "test_rmse: 0.6589953026259924\n",
      "test_r2: 0.3504795277327843\n",
      "feature number: 9\n",
      "train_rmse: 0.5740197085483204\n",
      "test_rmse: 0.6482825019788352\n",
      "test_r2: 0.3703332570152188\n",
      "feature number: 10\n",
      "train_rmse: 0.5683738583407798\n",
      "test_rmse: 0.6415633131733706\n",
      "test_r2: 0.38259426691083415\n",
      "feature number: 11\n",
      "train_rmse: 0.5616728010521578\n",
      "test_rmse: 0.6376891136842266\n",
      "test_r2: 0.39006969143867337\n",
      "feature number: 12\n",
      "train_rmse: 0.5611298940850338\n",
      "test_rmse: 0.6383389275492256\n",
      "test_r2: 0.38865091829674947\n",
      "feature number: 13\n",
      "train_rmse: 0.5524109529600192\n",
      "test_rmse: 0.6330716524516882\n",
      "test_r2: 0.39701536177372615\n",
      "feature number: 14\n",
      "train_rmse: 0.5496284210888205\n",
      "test_rmse: 0.6306917139255405\n",
      "test_r2: 0.4020880499935043\n",
      "feature number: 15\n",
      "train_rmse: 0.548498908938112\n",
      "test_rmse: 0.6310829159621218\n",
      "test_r2: 0.4011627375821569\n",
      "feature number: 16\n",
      "train_rmse: 0.5480285937623824\n",
      "test_rmse: 0.6316956831973567\n",
      "test_r2: 0.39997032443818364\n",
      "feature number: 17\n",
      "train_rmse: 0.5473136895306763\n",
      "test_rmse: 0.6346157303230535\n",
      "test_r2: 0.39430212894348815\n",
      "feature number: 18\n",
      "train_rmse: 0.5463117529014017\n",
      "test_rmse: 0.6409096257052525\n",
      "test_r2: 0.3822974140269444\n",
      "feature number: 19\n",
      "train_rmse: 0.5459627017494183\n",
      "test_rmse: 0.6423536222222727\n",
      "test_r2: 0.379465375378567\n",
      "feature number: 20\n",
      "train_rmse: 0.5420201090370275\n",
      "test_rmse: 0.6448998405314789\n",
      "test_r2: 0.3739235170218672\n",
      "Test_rmse_min = 1.fea_num: 14  2.rmse: 0.6306917139255405\n",
      "Test_r2_max = 1. fea_num: 14  2.r2: 0.4020880499935043\n",
      "./BayesianRidge_Pre_3/\n",
      "feature number: 2\n",
      "train_rmse: 0.5928217486273215\n",
      "test_rmse: 0.646585647097155\n",
      "test_r2: 0.370698679108309\n",
      "feature number: 3\n",
      "train_rmse: 0.5844720276614522\n",
      "test_rmse: 0.6511332225562532\n",
      "test_r2: 0.36485135531258117\n",
      "feature number: 4\n",
      "train_rmse: 0.5831209556536728\n",
      "test_rmse: 0.6568360159671985\n",
      "test_r2: 0.3545339642275792\n",
      "feature number: 5\n",
      "train_rmse: 0.5824025653306407\n",
      "test_rmse: 0.6594662460327358\n",
      "test_r2: 0.3493447817400817\n",
      "feature number: 6\n",
      "train_rmse: 0.5820069840234381\n",
      "test_rmse: 0.659608719896304\n",
      "test_r2: 0.34914455883802875\n",
      "feature number: 7\n",
      "train_rmse: 0.5817708592190032\n",
      "test_rmse: 0.6596553345534402\n",
      "test_r2: 0.3489464324693693\n",
      "feature number: 8\n",
      "train_rmse: 0.5807490080212043\n",
      "test_rmse: 0.6589953026259924\n",
      "test_r2: 0.3504795277327843\n",
      "feature number: 9\n",
      "train_rmse: 0.5740197085483204\n",
      "test_rmse: 0.6482825019788352\n",
      "test_r2: 0.3703332570152188\n",
      "feature number: 10\n",
      "train_rmse: 0.5683738583407798\n",
      "test_rmse: 0.6415633131733706\n",
      "test_r2: 0.38259426691083415\n",
      "feature number: 11\n",
      "train_rmse: 0.5616694095254756\n",
      "test_rmse: 0.6376799139862468\n",
      "test_r2: 0.3900824635345784\n",
      "feature number: 12\n",
      "train_rmse: 0.5611249641000312\n",
      "test_rmse: 0.6383284830863925\n",
      "test_r2: 0.38866450305855427\n",
      "feature number: 13\n",
      "train_rmse: 0.5524068802111263\n",
      "test_rmse: 0.6330710386084737\n",
      "test_r2: 0.397011075452537\n",
      "feature number: 14\n",
      "train_rmse: 0.5496239700076623\n",
      "test_rmse: 0.6306883477951887\n",
      "test_r2: 0.40208731625274047\n",
      "feature number: 15\n",
      "train_rmse: 0.5484918584046771\n",
      "test_rmse: 0.6310786560488091\n",
      "test_r2: 0.4011626423689493\n",
      "feature number: 16\n",
      "train_rmse: 0.5480228052584674\n",
      "test_rmse: 0.6316929867784972\n",
      "test_r2: 0.399969095000956\n",
      "feature number: 17\n",
      "train_rmse: 0.5473087402500948\n",
      "test_rmse: 0.6346172666740555\n",
      "test_r2: 0.39429350015847897\n",
      "feature number: 18\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_rmse: 0.5463074682467943\n",
      "test_rmse: 0.6409081063338103\n",
      "test_r2: 0.38229308352614166\n",
      "feature number: 19\n",
      "train_rmse: 0.5459588158279103\n",
      "test_rmse: 0.6423494494293135\n",
      "test_r2: 0.379465546860774\n",
      "feature number: 20\n",
      "train_rmse: 0.5419630951882063\n",
      "test_rmse: 0.6448431567128531\n",
      "test_r2: 0.3740035541492949\n",
      "Test_rmse_min = 1.fea_num: 14  2.rmse: 0.6306883477951887\n",
      "Test_r2_max = 1. fea_num: 14  2.r2: 0.40208731625274047\n",
      "./BayesianRidge_Pre_4/\n",
      "feature number: 2\n",
      "train_rmse: 0.5928217486273215\n",
      "test_rmse: 0.646585647097155\n",
      "test_r2: 0.370698679108309\n",
      "feature number: 3\n",
      "train_rmse: 0.5844720276614522\n",
      "test_rmse: 0.6511332225562532\n",
      "test_r2: 0.36485135531258117\n",
      "feature number: 4\n",
      "train_rmse: 0.5831209556536728\n",
      "test_rmse: 0.6568360159671985\n",
      "test_r2: 0.3545339642275792\n",
      "feature number: 5\n",
      "train_rmse: 0.5824025653306407\n",
      "test_rmse: 0.6594662460327358\n",
      "test_r2: 0.3493447817400817\n",
      "feature number: 6\n",
      "train_rmse: 0.5820069840234381\n",
      "test_rmse: 0.659608719896304\n",
      "test_r2: 0.34914455883802875\n",
      "feature number: 7\n",
      "train_rmse: 0.5817708592190032\n",
      "test_rmse: 0.6596553345534402\n",
      "test_r2: 0.3489464324693693\n",
      "feature number: 8\n",
      "train_rmse: 0.5807490080212043\n",
      "test_rmse: 0.6589953026259924\n",
      "test_r2: 0.3504795277327843\n",
      "feature number: 9\n",
      "train_rmse: 0.5740197085483204\n",
      "test_rmse: 0.6482825019788352\n",
      "test_r2: 0.3703332570152188\n",
      "feature number: 10\n",
      "train_rmse: 0.5683738583407798\n",
      "test_rmse: 0.6415633131733706\n",
      "test_r2: 0.38259426691083415\n",
      "feature number: 11\n",
      "train_rmse: 0.5616718788971925\n",
      "test_rmse: 0.637686243780174\n",
      "test_r2: 0.3900749232757201\n",
      "feature number: 12\n",
      "train_rmse: 0.5611294346812552\n",
      "test_rmse: 0.6383356231586458\n",
      "test_r2: 0.3886572340533534\n",
      "feature number: 13\n",
      "train_rmse: 0.5524104130359537\n",
      "test_rmse: 0.6330712186952532\n",
      "test_r2: 0.3970159855867681\n",
      "feature number: 14\n",
      "train_rmse: 0.5496277724196553\n",
      "test_rmse: 0.6306911092023164\n",
      "test_r2: 0.402088896186632\n",
      "feature number: 15\n",
      "train_rmse: 0.5484973393753603\n",
      "test_rmse: 0.6310834357615696\n",
      "test_r2: 0.401161485994001\n",
      "feature number: 16\n",
      "train_rmse: 0.5480270637493531\n",
      "test_rmse: 0.6316959641018869\n",
      "test_r2: 0.39996950820719174\n",
      "feature number: 17\n",
      "train_rmse: 0.5473124950371367\n",
      "test_rmse: 0.6346150839653308\n",
      "test_r2: 0.39430334545681167\n",
      "feature number: 18\n",
      "train_rmse: 0.5463107713213153\n",
      "test_rmse: 0.6409070090102865\n",
      "test_r2: 0.38230246662498796\n",
      "feature number: 19\n",
      "train_rmse: 0.5459619175862762\n",
      "test_rmse: 0.642350896645195\n",
      "test_r2: 0.37947036159404635\n",
      "feature number: 20\n",
      "train_rmse: 0.5420146020246739\n",
      "test_rmse: 0.6448917023320031\n",
      "test_r2: 0.37393893429281827\n",
      "Test_rmse_min = 1.fea_num: 14  2.rmse: 0.6306911092023164\n",
      "Test_r2_max = 1. fea_num: 14  2.r2: 0.402088896186632\n",
      "./BayesianRidge_Pre_5/\n",
      "feature number: 2\n",
      "train_rmse: 0.5928217486273215\n",
      "test_rmse: 0.646585647097155\n",
      "test_r2: 0.370698679108309\n",
      "feature number: 3\n",
      "train_rmse: 0.5844720276614522\n",
      "test_rmse: 0.6511332225562532\n",
      "test_r2: 0.36485135531258117\n",
      "feature number: 4\n",
      "train_rmse: 0.5831209556536728\n",
      "test_rmse: 0.6568360159671985\n",
      "test_r2: 0.3545339642275792\n",
      "feature number: 5\n",
      "train_rmse: 0.5824025653306407\n",
      "test_rmse: 0.6594662460327358\n",
      "test_r2: 0.3493447817400817\n",
      "feature number: 6\n",
      "train_rmse: 0.5820069840234381\n",
      "test_rmse: 0.659608719896304\n",
      "test_r2: 0.34914455883802875\n",
      "feature number: 7\n",
      "train_rmse: 0.5817708592190032\n",
      "test_rmse: 0.6596553345534402\n",
      "test_r2: 0.3489464324693693\n",
      "feature number: 8\n",
      "train_rmse: 0.5807490080212043\n",
      "test_rmse: 0.6589953026259924\n",
      "test_r2: 0.3504795277327843\n",
      "feature number: 9\n",
      "train_rmse: 0.5740197085483204\n",
      "test_rmse: 0.6482825019788352\n",
      "test_r2: 0.3703332570152188\n",
      "feature number: 10\n",
      "train_rmse: 0.5683738583407798\n",
      "test_rmse: 0.6415633131733706\n",
      "test_r2: 0.38259426691083415\n",
      "feature number: 11\n",
      "train_rmse: 0.5616674761779532\n",
      "test_rmse: 0.6376759704235669\n",
      "test_r2: 0.3900894873772067\n",
      "feature number: 12\n",
      "train_rmse: 0.5611233014971593\n",
      "test_rmse: 0.6383241596029834\n",
      "test_r2: 0.38867241296998967\n",
      "feature number: 13\n",
      "train_rmse: 0.5524058339320266\n",
      "test_rmse: 0.6330714427353402\n",
      "test_r2: 0.39701011523129226\n",
      "feature number: 14\n",
      "train_rmse: 0.5496228075793125\n",
      "test_rmse: 0.6306885446845315\n",
      "test_r2: 0.40208658568394934\n",
      "feature number: 15\n",
      "train_rmse: 0.5484896198985854\n",
      "test_rmse: 0.6310799112654022\n",
      "test_r2: 0.40115976046172797\n",
      "feature number: 16\n",
      "train_rmse: 0.5480206996385475\n",
      "test_rmse: 0.6316939170530114\n",
      "test_r2: 0.39996694218330797\n",
      "feature number: 17\n",
      "train_rmse: 0.5473070760615157\n",
      "test_rmse: 0.6346176031687703\n",
      "test_r2: 0.3942928851025557\n",
      "feature number: 18\n",
      "train_rmse: 0.5463059038624599\n",
      "test_rmse: 0.6409069956212582\n",
      "test_r2: 0.3822953710670867\n",
      "feature number: 19\n",
      "train_rmse: 0.5459574836201895\n",
      "test_rmse: 0.6423479189998589\n",
      "test_r2: 0.37946830198901194\n",
      "feature number: 20\n",
      "train_rmse: 0.5419566142380298\n",
      "test_rmse: 0.6448351584290163\n",
      "test_r2: 0.37401917660087813\n",
      "Test_rmse_min = 1.fea_num: 14  2.rmse: 0.6306885446845315\n",
      "Test_r2_max = 1. fea_num: 14  2.r2: 0.40208658568394934\n",
      "./BayesianRidge_Pre_6/\n",
      "feature number: 2\n",
      "train_rmse: 0.5928217486273215\n",
      "test_rmse: 0.646585647097155\n",
      "test_r2: 0.370698679108309\n",
      "feature number: 3\n",
      "train_rmse: 0.5844720276614522\n",
      "test_rmse: 0.6511332225562532\n",
      "test_r2: 0.36485135531258117\n",
      "feature number: 4\n",
      "train_rmse: 0.5831209556536728\n",
      "test_rmse: 0.6568360159671985\n",
      "test_r2: 0.3545339642275792\n",
      "feature number: 5\n",
      "train_rmse: 0.5824025653306407\n",
      "test_rmse: 0.6594662460327358\n",
      "test_r2: 0.3493447817400817\n",
      "feature number: 6\n",
      "train_rmse: 0.5820069840234381\n",
      "test_rmse: 0.659608719896304\n",
      "test_r2: 0.34914455883802875\n",
      "feature number: 7\n",
      "train_rmse: 0.5817708592190032\n",
      "test_rmse: 0.6596553345534402\n",
      "test_r2: 0.3489464324693693\n",
      "feature number: 8\n",
      "train_rmse: 0.5807490080212043\n",
      "test_rmse: 0.6589953026259924\n",
      "test_r2: 0.3504795277327843\n",
      "feature number: 9\n",
      "train_rmse: 0.5740197085483204\n",
      "test_rmse: 0.6482825019788352\n",
      "test_r2: 0.3703332570152188\n",
      "feature number: 10\n",
      "train_rmse: 0.5683738583407798\n",
      "test_rmse: 0.6415633131733706\n",
      "test_r2: 0.38259426691083415\n",
      "feature number: 11\n",
      "train_rmse: 0.568269735931958\n",
      "test_rmse: 0.6422544269354089\n",
      "test_r2: 0.381295062391624\n",
      "feature number: 12\n",
      "train_rmse: 0.5614542696818375\n",
      "test_rmse: 0.6390068022201738\n",
      "test_r2: 0.38742651068317313\n",
      "feature number: 13\n",
      "train_rmse: 0.5525377156303387\n",
      "test_rmse: 0.6329259184766259\n",
      "test_r2: 0.3972894645940167\n",
      "feature number: 14\n",
      "train_rmse: 0.5497855754298658\n",
      "test_rmse: 0.6304969408064526\n",
      "test_r2: 0.4024614289043734\n",
      "feature number: 15\n",
      "train_rmse: 0.5490849478436637\n",
      "test_rmse: 0.6307461745128242\n",
      "test_r2: 0.4019093917503729\n",
      "feature number: 16\n",
      "train_rmse: 0.5482458346509683\n",
      "test_rmse: 0.6315996263681065\n",
      "test_r2: 0.4001570610226576\n",
      "feature number: 17\n",
      "train_rmse: 0.5474719006107001\n",
      "test_rmse: 0.6345726871610338\n",
      "test_r2: 0.39434933158914176\n",
      "feature number: 18\n",
      "train_rmse: 0.5464421475389056\n",
      "test_rmse: 0.6410994888631489\n",
      "test_r2: 0.38191975571767267\n",
      "feature number: 19\n",
      "train_rmse: 0.546082688193981\n",
      "test_rmse: 0.6425976861014217\n",
      "test_r2: 0.3789998606266792\n",
      "feature number: 20\n",
      "train_rmse: 0.5425420866881485\n",
      "test_rmse: 0.6455278016236732\n",
      "test_r2: 0.3727910756410538\n",
      "Test_rmse_min = 1.fea_num: 14  2.rmse: 0.6304969408064526\n",
      "Test_r2_max = 1. fea_num: 14  2.r2: 0.4024614289043734\n",
      "./BayesianRidge_Pre_7/\n",
      "feature number: 2\n",
      "train_rmse: 0.5928217486273215\n",
      "test_rmse: 0.646585647097155\n",
      "test_r2: 0.370698679108309\n",
      "feature number: 3\n",
      "train_rmse: 0.5844720276614522\n",
      "test_rmse: 0.6511332225562532\n",
      "test_r2: 0.36485135531258117\n",
      "feature number: 4\n",
      "train_rmse: 0.5831209556536728\n",
      "test_rmse: 0.6568360159671985\n",
      "test_r2: 0.3545339642275792\n",
      "feature number: 5\n",
      "train_rmse: 0.5824025653306407\n",
      "test_rmse: 0.6594662460327358\n",
      "test_r2: 0.3493447817400817\n",
      "feature number: 6\n",
      "train_rmse: 0.5820069840234381\n",
      "test_rmse: 0.659608719896304\n",
      "test_r2: 0.34914455883802875\n",
      "feature number: 7\n",
      "train_rmse: 0.5817708592190032\n",
      "test_rmse: 0.6596553345534402\n",
      "test_r2: 0.3489464324693693\n",
      "feature number: 8\n",
      "train_rmse: 0.5807490080212043\n",
      "test_rmse: 0.6589953026259924\n",
      "test_r2: 0.3504795277327843\n",
      "feature number: 9\n",
      "train_rmse: 0.5740197085483204\n",
      "test_rmse: 0.6482825019788352\n",
      "test_r2: 0.3703332570152188\n",
      "feature number: 10\n",
      "train_rmse: 0.5683738583407798\n",
      "test_rmse: 0.6415633131733706\n",
      "test_r2: 0.38259426691083415\n",
      "feature number: 11\n",
      "train_rmse: 0.568269735931958\n",
      "test_rmse: 0.6422544269354089\n",
      "test_r2: 0.381295062391624\n",
      "feature number: 12\n",
      "train_rmse: 0.5611450167474727\n",
      "test_rmse: 0.6384197324269967\n",
      "test_r2: 0.3884534926582468\n",
      "feature number: 13\n",
      "train_rmse: 0.5524037506036045\n",
      "test_rmse: 0.6330532791206039\n",
      "test_r2: 0.39700241761238647\n",
      "feature number: 14\n",
      "train_rmse: 0.5496229917954912\n",
      "test_rmse: 0.6306442436576548\n",
      "test_r2: 0.40211777854732256\n",
      "feature number: 15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_rmse: 0.5489977944588103\n",
      "test_rmse: 0.6309090424928409\n",
      "test_r2: 0.40156610938717535\n",
      "feature number: 16\n",
      "train_rmse: 0.548011847249071\n",
      "test_rmse: 0.6315559262749826\n",
      "test_r2: 0.4001704584213247\n",
      "feature number: 17\n",
      "train_rmse: 0.5472923990757492\n",
      "test_rmse: 0.6345618407486624\n",
      "test_r2: 0.3943362121363597\n",
      "feature number: 18\n",
      "train_rmse: 0.5462939948416475\n",
      "test_rmse: 0.6408738846676534\n",
      "test_r2: 0.38227826281337285\n",
      "feature number: 19\n",
      "train_rmse: 0.5459433960989357\n",
      "test_rmse: 0.6423011087612187\n",
      "test_r2: 0.3794804581881894\n",
      "feature number: 20\n",
      "train_rmse: 0.5419598303390509\n",
      "test_rmse: 0.6447831681643836\n",
      "test_r2: 0.3740598104014512\n",
      "Test_rmse_min = 1.fea_num: 14  2.rmse: 0.6306442436576548\n",
      "Test_r2_max = 1. fea_num: 14  2.r2: 0.40211777854732256\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "n='Input_A1_020'  #改路徑\n",
    "#\n",
    "dire= ['./BayesianRidge_Pre_0/','./BayesianRidge_Pre_1/','./BayesianRidge_Pre_2/','./BayesianRidge_Pre_3/','./BayesianRidge_Pre_4/','./BayesianRidge_Pre_5/','./BayesianRidge_Pre_6/','./BayesianRidge_Pre_7/']\n",
    "# dire= ['../BayesianRidge_Pre_0/']\n",
    "print(n)\n",
    "for d in dire:\n",
    "    f_train_rmse=[]\n",
    "    f_test_rmse=[]\n",
    "    f_test_r2=[]\n",
    "    print(d)\n",
    "    data_d= d+n+'.csv'\n",
    "    data= pd.read_csv(data_d,index_col=0).drop(['Number'], axis=1)\n",
    "    y=data.Predict\n",
    "    skew_data=skew_pro(data)\n",
    "    num=skew_data.select_dtypes(exclude='object')\n",
    "    numcorr=num.corr()\n",
    "    f20=abs(numcorr['Predict']).sort_values(ascending=False).head(21).to_frame().index.to_numpy()[1:]\n",
    "    fea_list=[2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20]\n",
    "    for i in fea_list:\n",
    "        print('feature number:',i)\n",
    "        x=skew_data[f20[:i]]\n",
    "        tr_r,te_r, te_r2= lr_rmse_ave(x,y)\n",
    "        print('train_rmse:',tr_r)\n",
    "        print('test_rmse:',te_r)\n",
    "        print('test_r2:',te_r2)\n",
    "        f_train_rmse.append(tr_r)\n",
    "        f_test_rmse.append(te_r)\n",
    "        f_test_r2.append(te_r2)\n",
    "\n",
    "    test_r=np.array(f_test_rmse)\n",
    "    test_r2=np.array(f_test_r2)\n",
    "    test_r_min= np.where(test_r == np.amin(test_r))\n",
    "    test_r2_max= np.where(test_r2 == np.amax(test_r2))    \n",
    "    print('Test_rmse_min = 1.fea_num:', fea_list[test_r_min[0][0]], ' 2.rmse:' ,np.amin(test_r))\n",
    "    print('Test_r2_max = 1. fea_num:', fea_list[test_r2_max[0][0]],  ' 2.r2:', np.amax(test_r2))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Input_A4_020', 'Input_A3_020', 'Input_A5_020', 'Input_A6_020',\n",
       "       'Input_A2_020', 'Input_A1_021', 'Input_A2_021', 'Input_A2_015',\n",
       "       'Input_C_001', 'Input_A1_016', 'Input_C_060', 'Input_A1_019',\n",
       "       'Input_A4_011', 'Input_A2_019'], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fea_number=14\n",
    "data=pd.read_csv('./BayesianRidge_Pre_0/Input_A1_020.csv',index_col=0).drop(['Number'], axis=1)\n",
    "y=data.Predict\n",
    "skew_data=skew_pro(data)\n",
    "num=skew_data.select_dtypes(exclude='object')\n",
    "numcorr=num.corr()\n",
    "title=abs(numcorr['Predict']).sort_values(ascending=False).head(fea_number+1).to_frame().index.to_numpy()[1:]\n",
    "title"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lr_rmse_ave_fea(data,fea_num):\n",
    "    \n",
    "    num=data.select_dtypes(exclude='object')\n",
    "    numcorr=num.corr()\n",
    "    cols=abs(numcorr['Predict']).sort_values(ascending=False).head(fea_num+1).to_frame().index.to_numpy()[1:]\n",
    "    y = data['Predict']\n",
    "    X= data[cols]\n",
    "    train_rmse=[]\n",
    "    test_rmse=[]\n",
    "    test_r2=[]\n",
    "    \n",
    "    for i in np.arange(10):\n",
    "        x_train,x_test,y_train,y_test = train_test_split(X,y, random_state = i)\n",
    "        lr = LinearRegression().fit(x_train,y_train)\n",
    "\n",
    "        y_train_pred = lr.predict(x_train)\n",
    "        y_test_pred = lr.predict(x_test)\n",
    "        train_rmse.append(mean_squared_error(y_train, y_train_pred,squared=False))\n",
    "        test_rmse.append(mean_squared_error(y_test, y_test_pred,squared=False))\n",
    "        test_r2.append(r2_score(y_test,y_test_pred))\n",
    "    \n",
    "    train_rmse=np.array(train_rmse).mean()\n",
    "    test_rmse=np.array(test_rmse).mean()\n",
    "    test_r2=np.array(test_r2).mean()\n",
    "    \n",
    "    print('train_rmse:', train_rmse)\n",
    "    print('test_rmse:', test_rmse)\n",
    "    print('test_r2:', test_r2)\n",
    "#     return train_rmse, test_rmse, test_r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_rmse: 0.5496703758835424\n",
      "test_rmse: 0.630685153741493\n",
      "test_r2: 0.4021163900449416\n"
     ]
    }
   ],
   "source": [
    "lr_rmse_ave_fea(skew_data,14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def laso_alpha(x,y,parameters):\n",
    "    from sklearn.linear_model import Lasso\n",
    "    \n",
    "    para=[]\n",
    "\n",
    "    for i in np.arange(10):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=i)\n",
    "        lasso=Lasso()\n",
    "        lasso_reg=GridSearchCV(lasso, param_grid=parameters, scoring='neg_mean_squared_error', cv=3)\n",
    "        lasso_reg.fit(X_train,y_train)\n",
    "        para.append(lasso_reg.best_params_)\n",
    "\n",
    "    print(para)\n",
    "    \n",
    "def laso_rmse_ave(x,y,alp):\n",
    "    from sklearn.linear_model import Lasso\n",
    "    \n",
    "    rmse=[]\n",
    "    r2=[]\n",
    "\n",
    "    for i in np.arange(10):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=i)\n",
    "        lasso_mod=Lasso(alpha=alp)\n",
    "        lasso_mod.fit(X_train,y_train)\n",
    "        y_lasso_train=lasso_mod.predict(X_train)\n",
    "        y_lasso_test=lasso_mod.predict(X_test)\n",
    "        rmse.append(math.sqrt(mean_squared_error(y_test, y_lasso_test)))\n",
    "        r2.append(r2_score(y_test, y_lasso_test))\n",
    "    \n",
    "    test_rmse=np.array(rmse).mean()\n",
    "    print('test_rmse_ave:',test_rmse)\n",
    "    print(rmse)\n",
    "    print('\\n')\n",
    "    test_r2=np.array(r2).mean()\n",
    "    print('test_r2_ave:',test_r2)\n",
    "    print(r2)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'alpha': 0.01}, {'alpha': 0.01}, {'alpha': 0.01}, {'alpha': 0.01}, {'alpha': 0.01}, {'alpha': 0.009}, {'alpha': 0.01}, {'alpha': 0.02}, {'alpha': 0.02}, {'alpha': 0.02}]\n"
     ]
    }
   ],
   "source": [
    "parameters= {'alpha':[0.009,0.01,0.02,0.005]}\n",
    "laso_alpha(skew_data[title],y,parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_rmse_ave: 0.5966543862816749\n",
      "[0.46620984911224955, 0.6741264570147933, 0.8203464865214706, 0.4369860546979481, 0.6401251047894848, 0.7456655545103595, 0.7047084919188028, 0.6229993612177261, 0.4866207589069143, 0.36875574412700046]\n",
      "\n",
      "\n",
      "test_r2_ave: 0.4172470972694066\n",
      "[0.5921123062469382, 0.33779988139965444, 0.41364601517656396, 0.4194992900160419, 0.5331287816228147, 0.23563419886713255, 0.32234871859884107, 0.3085633111767526, 0.4348570496571701, 0.5748814199321561]\n"
     ]
    }
   ],
   "source": [
    "laso_rmse_ave(skew_data[title],y,0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ElasticNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score(y_pred):\n",
    "    return str(math.sqrt(mean_squared_error(y_test, y_pred)))\n",
    "\n",
    "def ElasticNet_alpha(x,y,alphas,l1ratio):\n",
    "    from sklearn.linear_model import ElasticNetCV\n",
    "    \n",
    "    alpha_=[]\n",
    "    l1_ratio_=[]\n",
    "\n",
    "    for i in np.arange(10):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=i)\n",
    "        elastic_cv = ElasticNetCV(cv=3, max_iter=1e7, alphas=alphas,  l1_ratio=l1ratio)\n",
    "        elasticmod = elastic_cv.fit(X_train, y_train.ravel())\n",
    "\n",
    "        alpha_.append(elastic_cv.alpha_)\n",
    "        l1_ratio_.append(elastic_cv.l1_ratio_)\n",
    "\n",
    "    print('alpha')\n",
    "    print(alpha_)\n",
    "    print('\\n')\n",
    "    print('l1_ratio')\n",
    "    print(l1_ratio_)\n",
    "    \n",
    "def ElasticNet_rmse_ave(x,y,alp,l1r):\n",
    "    from sklearn.linear_model import ElasticNet\n",
    "    \n",
    "    rmse=[]\n",
    "    r2=[]\n",
    "\n",
    "    for i in np.arange(10):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=i)\n",
    "        ElasticNet_mod=ElasticNet(alpha=alp, l1_ratio=l1r)\n",
    "        ElasticNet_mod.fit(X_train,y_train)\n",
    "        y_ElasticNet_train=ElasticNet_mod.predict(X_train)\n",
    "        y_ElasticNet_test=ElasticNet_mod.predict(X_test)\n",
    "        rmse.append(math.sqrt(mean_squared_error(y_test, y_ElasticNet_test)))\n",
    "        r2.append(r2_score(y_test, y_ElasticNet_test))\n",
    "    \n",
    "    test_rmse=np.array(rmse).mean()\n",
    "    print('test_rmse_ave:',test_rmse)\n",
    "    print(rmse)\n",
    "    print('\\n')\n",
    "    test_r2=np.array(r2).mean()\n",
    "    print('test_r2_ave:',test_r2)\n",
    "    print(r2)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha\n",
      "[0.09, 0.09, 0.09, 0.09, 0.09, 0.09, 0.09, 0.09, 0.09, 0.09]\n",
      "\n",
      "\n",
      "l1_ratio\n",
      "[0.02, 0.04, 0.02, 0.02, 0.02, 0.02, 0.02, 0.08, 0.03, 0.05]\n"
     ]
    }
   ],
   "source": [
    "# alphas = [10,1,0.1,0.01,0.001,0.002,0.003,0.004,0.005,0.00054255]\n",
    "alphas =[0.09]\n",
    "# alphas =[0.07,0.06,0.05,0.04, 0.03,0.02]\n",
    "l1ratio = [0.02,0.03,0.04,0.05,0.08,]\n",
    "ElasticNet_alpha(skew_data[title],y,alphas,l1ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_rmse_ave: 0.5899816492677211\n",
      "[0.471493396911073, 0.6503581355816648, 0.8399015358747844, 0.4255020295801734, 0.643091779783245, 0.7324902145547428, 0.714958298947838, 0.5941570359776989, 0.478868904597491, 0.34899516086850063]\n",
      "\n",
      "\n",
      "test_r2_ave: 0.4338190480252001\n",
      "[0.5828147508562611, 0.3836723310827619, 0.38535834861637475, 0.4496095730017958, 0.5287913022957005, 0.2624070804541806, 0.30249282821691914, 0.3711027346564324, 0.4527190577421931, 0.6192224733293814]\n"
     ]
    }
   ],
   "source": [
    "ElasticNet_rmse_ave(skew_data[title],y,[0.09],0.02)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best params\n",
      "{'C': 1.2, 'epsilon': 0.4, 'gamma': 1e-07, 'kernel': 'linear'}\n",
      "\n",
      "\n",
      "best params\n",
      "{'C': 1, 'epsilon': 0.4, 'gamma': 1e-07, 'kernel': 'linear'}\n",
      "\n",
      "\n",
      "best params\n",
      "{'C': 1.4, 'epsilon': 0.4, 'gamma': 1e-07, 'kernel': 'linear'}\n",
      "\n",
      "\n",
      "best params\n",
      "{'C': 1.4, 'epsilon': 0.4, 'gamma': 1e-07, 'kernel': 'linear'}\n",
      "\n",
      "\n",
      "best params\n",
      "{'C': 1, 'epsilon': 0.4, 'gamma': 1e-07, 'kernel': 'linear'}\n",
      "\n",
      "\n",
      "best params\n",
      "{'C': 1.2, 'epsilon': 0.4, 'gamma': 1e-07, 'kernel': 'linear'}\n",
      "\n",
      "\n",
      "best params\n",
      "{'C': 1.4, 'epsilon': 0.4, 'gamma': 1e-07, 'kernel': 'linear'}\n",
      "\n",
      "\n",
      "best params\n",
      "{'C': 1.5, 'epsilon': 0.4, 'gamma': 1e-07, 'kernel': 'linear'}\n",
      "\n",
      "\n",
      "best params\n",
      "{'C': 1, 'epsilon': 0.4, 'gamma': 1e-07, 'kernel': 'linear'}\n",
      "\n",
      "\n",
      "best params\n",
      "{'C': 1.5, 'epsilon': 0.4, 'gamma': 1e-07, 'kernel': 'linear'}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# parameters = {'kernel': ('linear', 'rbf','poly'), 'C':[1.2,1.3,1,1.5],'gamma': [1e-7,1e-6 1e-8,5e-7],'epsilon':[0.2,0.5,0.3,0.4]}\n",
    "for i in np.arange(10):\n",
    "    X_SVR_train, X_SVR_test, y_SVR_train, y_SVR_test = train_test_split(skew_data[title], y, test_size=0.2, random_state=i)\n",
    "    parameters = {'kernel': ['linear'], 'C':[1.2,1.3,1,1.4,1.5],'gamma': [1e-7,],'epsilon':[0.4]}\n",
    "    clf = GridSearchCV(estimator = SVR(), param_grid = parameters , n_jobs=6,iid=False, verbose=0,scoring='neg_mean_squared_error')\n",
    "    clf.fit(X_SVR_train,y_SVR_train)\n",
    "    print('best params')\n",
    "    print (clf.best_params_)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#best params {'C': 1.3, 'epsilon': 0.4, 'gamma': 1e-07, 'kernel': 'linear'}\n",
    "def svr_rmse_ave(data,fea_num,model):\n",
    "    \n",
    "    num=data.select_dtypes(exclude='object')\n",
    "    numcorr=num.corr()\n",
    "    title=abs(numcorr['Predict']).sort_values(ascending=False).head(fea_num+1).to_frame().index.to_numpy()[1:]\n",
    "    y = data['Predict']\n",
    "    X= data[title]\n",
    "    train_rmse=[]\n",
    "    test_rmse=[]\n",
    "    test_r2=[]\n",
    "    \n",
    "    for i in np.arange(10):\n",
    "        x_train,x_test,y_train,y_test = train_test_split(X,y, random_state = i)\n",
    "        svr = model.fit(x_train,y_train)\n",
    "        y_train_pred = svr.predict(x_train)\n",
    "        y_test_pred = svr.predict(x_test)\n",
    "        train_rmse.append(mean_squared_error(y_train, y_train_pred,squared=False))\n",
    "        test_rmse.append(mean_squared_error(y_test, y_test_pred,squared=False))\n",
    "        test_r2.append(r2_score(y_test,y_test_pred))\n",
    "    \n",
    "    train_rmse=np.array(train_rmse).mean()\n",
    "    test_rmse=np.array(test_rmse).mean()\n",
    "    test_r2=np.array(test_r2).mean()\n",
    "    \n",
    "    print('train_rmse:', train_rmse)\n",
    "    print('test_rmse:', test_rmse)\n",
    "    print('test_r2:', test_r2)\n",
    "#     return train_rmse, test_rmse, test_r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_rmse: 0.5648260361049923\n",
      "test_rmse: 0.6284314864841181\n",
      "test_r2: 0.409871488238135\n"
     ]
    }
   ],
   "source": [
    "model=SVR(kernel='linear', C=1.3, gamma= 1e-07, epsilon= 0.4)\n",
    "svr_rmse_ave(skew_data,14,model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xgb_ave(x,y,model):\n",
    "    \n",
    "    rmse=[]\n",
    "    r2=[]\n",
    "\n",
    "    for i in np.arange(10):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=i)\n",
    "        model.fit(X_train,y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        rmse.append(math.sqrt(mean_squared_error(y_test, y_pred )))\n",
    "        r2.append(r2_score(y_test, y_pred ))\n",
    "    \n",
    "    test_rmse=np.array(rmse).mean()\n",
    "    print('test_rmse_ave:',test_rmse)\n",
    "    print(rmse)\n",
    "    print('\\n')\n",
    "    test_r2=np.array(r2).mean()\n",
    "    print('test_r2_ave:',test_r2)\n",
    "    print(r2)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 先調 booster / n_estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:47:48] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "best params\n",
      "{'booster': 'dart', 'n_estimators': 20}\n",
      "\n",
      "\n",
      "[02:47:57] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "best params\n",
      "{'booster': 'dart', 'n_estimators': 20}\n",
      "\n",
      "\n",
      "[02:48:04] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "best params\n",
      "{'booster': 'dart', 'n_estimators': 30}\n",
      "\n",
      "\n",
      "[02:48:12] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "best params\n",
      "{'booster': 'dart', 'n_estimators': 20}\n",
      "\n",
      "\n",
      "[02:48:19] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "best params\n",
      "{'booster': 'dart', 'n_estimators': 20}\n",
      "\n",
      "\n",
      "[02:48:26] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "best params\n",
      "{'booster': 'dart', 'n_estimators': 50}\n",
      "\n",
      "\n",
      "[02:48:34] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "best params\n",
      "{'booster': 'dart', 'n_estimators': 40}\n",
      "\n",
      "\n",
      "[02:48:41] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "best params\n",
      "{'booster': 'dart', 'n_estimators': 40}\n",
      "\n",
      "\n",
      "[02:48:48] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "best params\n",
      "{'booster': 'dart', 'n_estimators': 20}\n",
      "\n",
      "\n",
      "[02:48:57] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "best params\n",
      "{'booster': 'dart', 'n_estimators': 30}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#for tuning parameters\n",
    "parameters_for_testing = {\n",
    "#     'booster':['gbtree','gblinear','dart'],\n",
    "    'booster':['dart'],\n",
    "    'n_estimators':range(10,201,10),\n",
    "}\n",
    "\n",
    "other_params = {'learning_rate': 0.1, 'n_estimators': 90, 'max_depth': 5, 'min_child_weight': 1, 'seed': 42,\n",
    "'subsample': 0.8, 'colsample_bytree': 0.8, 'gamma': 0, 'reg_alpha': 0, 'reg_lambda': 1}\n",
    "\n",
    "for i in np.arange(10):\n",
    "    X_XGB_train, X_XGB_test, y_XGB_train, y_XGB_test = train_test_split(skew_data[title], y, test_size=0.2, random_state=i)\n",
    "    xgb_model = XGBRegressor(**other_params)\n",
    "    gsearch = GridSearchCV(estimator = xgb_model, param_grid = parameters_for_testing, n_jobs=6,iid=False, verbose=0,scoring='neg_mean_squared_error')\n",
    "    gsearch.fit(X_XGB_train,y_XGB_train)\n",
    "    print('best params')\n",
    "    print (gsearch.best_params_)\n",
    "    print('\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 調 max_depth / min_child_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:53:39] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "best params\n",
      "{'max_depth': 5, 'min_child_weight': 4}\n",
      "\n",
      "\n",
      "[02:53:40] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "best params\n",
      "{'max_depth': 5, 'min_child_weight': 6}\n",
      "\n",
      "\n",
      "[02:53:41] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "best params\n",
      "{'max_depth': 5, 'min_child_weight': 5}\n",
      "\n",
      "\n",
      "[02:53:41] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "best params\n",
      "{'max_depth': 5, 'min_child_weight': 3}\n",
      "\n",
      "\n",
      "[02:53:42] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "best params\n",
      "{'max_depth': 5, 'min_child_weight': 1}\n",
      "\n",
      "\n",
      "[02:53:42] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "best params\n",
      "{'max_depth': 5, 'min_child_weight': 2}\n",
      "\n",
      "\n",
      "[02:53:43] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "best params\n",
      "{'max_depth': 5, 'min_child_weight': 3}\n",
      "\n",
      "\n",
      "[02:53:43] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "best params\n",
      "{'max_depth': 5, 'min_child_weight': 5}\n",
      "\n",
      "\n",
      "[02:53:44] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "best params\n",
      "{'max_depth': 5, 'min_child_weight': 4}\n",
      "\n",
      "\n",
      "[02:53:45] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "best params\n",
      "{'max_depth': 5, 'min_child_weight': 6}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# {'booster': 'dart', 'n_estimators': 30}\n",
    "\n",
    "parameters_for_testing = {\n",
    "#     'max_depth': [1,2,3, 4, 5, 6, 7, 8, 9, 10],\n",
    "    'max_depth': [5], \n",
    "    'min_child_weight': [1, 2, 3, 4, 5, 6]\n",
    "}\n",
    "\n",
    "other_params = {'booster':'dart','learning_rate': 0.1, 'n_estimators': 30, 'seed': 42,\n",
    "'subsample': 0.8, 'colsample_bytree': 0.8, 'gamma': 0, 'reg_alpha': 0, 'reg_lambda': 1}\n",
    "\n",
    "for i in np.arange(10):\n",
    "    X_XGB_train, X_XGB_test, y_XGB_train, y_XGB_test = train_test_split(skew_data[title], y, test_size=0.2, random_state=i)\n",
    "    xgb_model = XGBRegressor(**other_params)\n",
    "    gsearch = GridSearchCV(estimator = xgb_model, param_grid = parameters_for_testing, n_jobs=6,iid=False, verbose=0,scoring='neg_mean_squared_error')\n",
    "    gsearch.fit(X_XGB_train,y_XGB_train)\n",
    "    print('best params')\n",
    "    print (gsearch.best_params_)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 調 gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:54:38] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "best params\n",
      "{'gamma': 0}\n",
      "\n",
      "\n",
      "[02:54:39] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "best params\n",
      "{'gamma': 0.4}\n",
      "\n",
      "\n",
      "[02:54:39] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "best params\n",
      "{'gamma': 0.3}\n",
      "\n",
      "\n",
      "[02:54:40] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "best params\n",
      "{'gamma': 0}\n",
      "\n",
      "\n",
      "[02:54:41] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "best params\n",
      "{'gamma': 0.3}\n",
      "\n",
      "\n",
      "[02:54:42] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "best params\n",
      "{'gamma': 0.1}\n",
      "\n",
      "\n",
      "[02:54:43] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "best params\n",
      "{'gamma': 0.2}\n",
      "\n",
      "\n",
      "[02:54:43] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "best params\n",
      "{'gamma': 0.4}\n",
      "\n",
      "\n",
      "[02:54:44] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "best params\n",
      "{'gamma': 0}\n",
      "\n",
      "\n",
      "[02:54:45] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "best params\n",
      "{'gamma': 0}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# {'max_depth': 5, 'min_child_weight': 4}\n",
    "parameters_for_testing = {\n",
    "    'gamma': [0,0.1, 0.2, 0.3, 0.4, 0.5, 0.6]\n",
    "}\n",
    "\n",
    "other_params = {'booster':'dart','learning_rate': 0.1, 'n_estimators': 30, 'max_depth': 5, 'min_child_weight': 4, 'seed': 42,\n",
    "'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0, 'reg_lambda': 1}\n",
    "\n",
    "for i in np.arange(10):\n",
    "    X_XGB_train, X_XGB_test, y_XGB_train, y_XGB_test = train_test_split(skew_data[title], y, test_size=0.2, random_state=i)\n",
    "    xgb_model = XGBRegressor(**other_params)\n",
    "    gsearch = GridSearchCV(estimator = xgb_model, param_grid = parameters_for_testing, n_jobs=6,iid=False, verbose=0,scoring='neg_mean_squared_error')\n",
    "    gsearch.fit(X_XGB_train,y_XGB_train)\n",
    "    print('best params')\n",
    "    print (gsearch.best_params_)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 調 subsample / colsample_bytree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:59:43] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "best params\n",
      "{'colsample_bytree': 0.5, 'subsample': 0.2}\n",
      "\n",
      "\n",
      "[02:59:44] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "best params\n",
      "{'colsample_bytree': 0.5, 'subsample': 0.2}\n",
      "\n",
      "\n",
      "[02:59:44] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "best params\n",
      "{'colsample_bytree': 0.5, 'subsample': 0.5}\n",
      "\n",
      "\n",
      "[02:59:45] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "best params\n",
      "{'colsample_bytree': 0.5, 'subsample': 0.8}\n",
      "\n",
      "\n",
      "[02:59:46] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "best params\n",
      "{'colsample_bytree': 0.5, 'subsample': 0.2}\n",
      "\n",
      "\n",
      "[02:59:46] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "best params\n",
      "{'colsample_bytree': 0.5, 'subsample': 0.4}\n",
      "\n",
      "\n",
      "[02:59:47] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "best params\n",
      "{'colsample_bytree': 0.5, 'subsample': 0.2}\n",
      "\n",
      "\n",
      "[02:59:48] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "best params\n",
      "{'colsample_bytree': 0.5, 'subsample': 0.7}\n",
      "\n",
      "\n",
      "[02:59:49] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "best params\n",
      "{'colsample_bytree': 0.5, 'subsample': 0.3}\n",
      "\n",
      "\n",
      "[02:59:50] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "best params\n",
      "{'colsample_bytree': 0.5, 'subsample': 0.3}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# {'gamma': 0.2}\n",
    "parameters_for_testing = {\n",
    "#     'colsample_bytree': [0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],\n",
    "    'colsample_bytree': [0.5],\n",
    "    'subsample': [0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9] \n",
    "}\n",
    "\n",
    "other_params = {'booster':'dart','learning_rate': 0.1, 'n_estimators': 30, 'max_depth': 5, 'min_child_weight': 4, 'seed': 42,\n",
    " 'reg_alpha': 0, 'reg_lambda': 1, 'gamma':0.2}\n",
    "\n",
    "for i in np.arange(10):\n",
    "    X_XGB_train, X_XGB_test, y_XGB_train, y_XGB_test = train_test_split(skew_data[title], y, test_size=0.2, random_state=i)\n",
    "    xgb_model = XGBRegressor(**other_params)\n",
    "    gsearch = GridSearchCV(estimator = xgb_model, param_grid = parameters_for_testing, n_jobs=6,iid=False, verbose=0,scoring='neg_mean_squared_error')\n",
    "    gsearch.fit(X_XGB_train,y_XGB_train)\n",
    "    print('best params')\n",
    "    print (gsearch.best_params_)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### reg_alpha / reg_lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[03:03:07] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "best params\n",
      "{'reg_alpha': 0.5, 'reg_lambda': 3}\n",
      "\n",
      "\n",
      "[03:03:07] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "best params\n",
      "{'reg_alpha': 0.5, 'reg_lambda': 3}\n",
      "\n",
      "\n",
      "[03:03:08] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "best params\n",
      "{'reg_alpha': 0.5, 'reg_lambda': 0.05}\n",
      "\n",
      "\n",
      "[03:03:08] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "best params\n",
      "{'reg_alpha': 0.5, 'reg_lambda': 3}\n",
      "\n",
      "\n",
      "[03:03:09] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "best params\n",
      "{'reg_alpha': 0.5, 'reg_lambda': 2}\n",
      "\n",
      "\n",
      "[03:03:09] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "best params\n",
      "{'reg_alpha': 0.5, 'reg_lambda': 0.1}\n",
      "\n",
      "\n",
      "[03:03:10] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "best params\n",
      "{'reg_alpha': 0.5, 'reg_lambda': 0.05}\n",
      "\n",
      "\n",
      "[03:03:10] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "best params\n",
      "{'reg_alpha': 0.5, 'reg_lambda': 0.5}\n",
      "\n",
      "\n",
      "[03:03:11] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "best params\n",
      "{'reg_alpha': 0.5, 'reg_lambda': 0.05}\n",
      "\n",
      "\n",
      "[03:03:11] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "best params\n",
      "{'reg_alpha': 0.5, 'reg_lambda': 1}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# {'colsample_bytree': 0.5, 'subsample': 0.4}\n",
    "\n",
    "parameters_for_testing = {\n",
    "#     'reg_alpha': [0,0.05, 0.1, 0.5 , 1, 2, 3], \n",
    "    'reg_alpha': [0.5],     \n",
    "    'reg_lambda': [0.05, 0.1, 0.5 , 1, 2, 3]\n",
    "}\n",
    "\n",
    "other_params = {'booster':'dart','learning_rate': 0.1, 'n_estimators': 30, 'max_depth': 5, 'min_child_weight': 4, 'seed': 42,\n",
    " 'gamma':0.2,'subsample':0.4,'colsample_bytree': 0.5}\n",
    "\n",
    "\n",
    "for i in np.arange(10):\n",
    "    X_XGB_train, X_XGB_test, y_XGB_train, y_XGB_test = train_test_split(skew_data[title], y, test_size=0.2, random_state=i)\n",
    "    xgb_model = XGBRegressor(**other_params)\n",
    "    gsearch = GridSearchCV(estimator = xgb_model, param_grid = parameters_for_testing, n_jobs=6,iid=False, verbose=0,scoring='neg_mean_squared_error')\n",
    "    gsearch.fit(X_XGB_train,y_XGB_train)\n",
    "    print('best params')\n",
    "    print (gsearch.best_params_)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[03:05:29] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "best params\n",
      "{'learning_rate': 0.07}\n",
      "\n",
      "\n",
      "[03:05:29] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "best params\n",
      "{'learning_rate': 0.1}\n",
      "\n",
      "\n",
      "[03:05:30] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "best params\n",
      "{'learning_rate': 0.1}\n",
      "\n",
      "\n",
      "[03:05:30] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "best params\n",
      "{'learning_rate': 0.1}\n",
      "\n",
      "\n",
      "[03:05:30] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "best params\n",
      "{'learning_rate': 0.1}\n",
      "\n",
      "\n",
      "[03:05:31] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "best params\n",
      "{'learning_rate': 0.1}\n",
      "\n",
      "\n",
      "[03:05:31] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "best params\n",
      "{'learning_rate': 0.1}\n",
      "\n",
      "\n",
      "[03:05:32] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "best params\n",
      "{'learning_rate': 0.1}\n",
      "\n",
      "\n",
      "[03:05:33] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "best params\n",
      "{'learning_rate': 0.07}\n",
      "\n",
      "\n",
      "[03:05:33] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "best params\n",
      "{'learning_rate': 0.1}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# {'reg_alpha': 0.5, 'reg_lambda': 1.5}\n",
    "\n",
    "parameters_for_testing = {\n",
    "   'learning_rate': [0.01, 0.05, 0.07, 0.1, 0.2]\n",
    "}\n",
    "\n",
    "other_params = {'booster':'dart', 'n_estimators': 30, 'max_depth': 5, 'min_child_weight': 4, 'seed': 42,\n",
    " 'gamma':0.2,'subsample':0.4,'colsample_bytree': 0.5,'reg_alpha': 0.5, 'reg_lambda': 1.5}\n",
    "\n",
    "for i in np.arange(10):\n",
    "    X_XGB_train, X_XGB_test, y_XGB_train, y_XGB_test = train_test_split(skew_data[title], y, test_size=0.2, random_state=i)\n",
    "    xgb_model = XGBRegressor(**other_params)\n",
    "    gsearch = GridSearchCV(estimator = xgb_model, param_grid = parameters_for_testing, n_jobs=6,iid=False, verbose=0,scoring='neg_mean_squared_error')\n",
    "    gsearch.fit(X_XGB_train,y_XGB_train)\n",
    "    print('best params')\n",
    "    print (gsearch.best_params_)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_rmse_ave: 0.5538214827832086\n",
      "[0.415311279394196, 0.5479720012596659, 0.8479936716277775, 0.39496177295789897, 0.6421760293128854, 0.6499519208695562, 0.6900304877959511, 0.6119958926029, 0.38985330346548364, 0.3479684685457719]\n",
      "\n",
      "\n",
      "test_r2_ave: 0.5029196661832124\n",
      "[0.6763130676748439, 0.562454473777501, 0.3734576111103507, 0.5257823356859532, 0.5301323312728741, 0.41926828050926446, 0.3502836235533211, 0.3327720472170135, 0.6372733304228446, 0.621459560608157]\n"
     ]
    }
   ],
   "source": [
    "best_xgb_model = XGBRegressor(\n",
    "                objective ='reg:squarederror',\n",
    "              learning_rate = 0.09,\n",
    "              booster = 'gbtree', \n",
    "              n_estimators = 30, \n",
    "              max_depth = 5, \n",
    "              min_child_weight = 4,\n",
    "              seed = 42,\n",
    "              gamma = 0.2,\n",
    "              subsample = 0.4,\n",
    "              colsample_bytree = 0.5,\n",
    "              reg_alpha =  0.5,\n",
    "              reg_lambda = 1.5)\n",
    "xgb_ave(skew_data[title], y,best_xgb_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rand_ave(x,y,model):\n",
    "    \n",
    "    rmse=[]\n",
    "    r2=[]\n",
    "\n",
    "    for i in np.arange(10):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=i)\n",
    "        model.fit(X_train,y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        rmse.append(math.sqrt(mean_squared_error(y_test, y_pred )))\n",
    "        r2.append(r2_score(y_test, y_pred ))\n",
    "    \n",
    "    test_rmse=np.array(rmse).mean()\n",
    "    print('test_rmse_ave:',test_rmse)\n",
    "    print(rmse)\n",
    "    print('\\n')\n",
    "    test_r2=np.array(r2).mean()\n",
    "    print('test_r2_ave:',test_r2)\n",
    "    print(r2)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "clf = RandomForestRegressor(\n",
    "          criterion ='mse', \n",
    "          random_state = 42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_RAND_train, X_RAND_test, y_RAND_train, y_RAND_test = train_test_split(skew_data[title], y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 360 candidates, totalling 1800 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done   1 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=6)]: Done   6 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=6)]: Done  13 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=6)]: Done  20 tasks      | elapsed:    3.6s\n",
      "[Parallel(n_jobs=6)]: Done  29 tasks      | elapsed:    7.0s\n",
      "[Parallel(n_jobs=6)]: Done  38 tasks      | elapsed:    8.5s\n",
      "[Parallel(n_jobs=6)]: Done  49 tasks      | elapsed:   13.6s\n",
      "[Parallel(n_jobs=6)]: Done  60 tasks      | elapsed:   16.0s\n",
      "[Parallel(n_jobs=6)]: Done  73 tasks      | elapsed:   19.4s\n",
      "[Parallel(n_jobs=6)]: Done  86 tasks      | elapsed:   22.0s\n",
      "[Parallel(n_jobs=6)]: Done 101 tasks      | elapsed:   26.5s\n",
      "[Parallel(n_jobs=6)]: Done 116 tasks      | elapsed:   30.1s\n",
      "[Parallel(n_jobs=6)]: Done 133 tasks      | elapsed:   34.0s\n",
      "[Parallel(n_jobs=6)]: Done 150 tasks      | elapsed:   39.0s\n",
      "[Parallel(n_jobs=6)]: Done 169 tasks      | elapsed:   43.2s\n",
      "[Parallel(n_jobs=6)]: Done 188 tasks      | elapsed:   47.4s\n",
      "[Parallel(n_jobs=6)]: Done 209 tasks      | elapsed:   53.0s\n",
      "[Parallel(n_jobs=6)]: Done 230 tasks      | elapsed:   58.6s\n",
      "[Parallel(n_jobs=6)]: Done 253 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=6)]: Done 276 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=6)]: Done 301 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=6)]: Done 326 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=6)]: Done 353 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=6)]: Done 380 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=6)]: Done 409 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=6)]: Done 438 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=6)]: Done 469 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=6)]: Done 500 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=6)]: Done 533 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=6)]: Done 566 tasks      | elapsed:  2.5min\n",
      "[Parallel(n_jobs=6)]: Done 601 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=6)]: Done 636 tasks      | elapsed:  2.8min\n",
      "[Parallel(n_jobs=6)]: Done 673 tasks      | elapsed:  3.0min\n",
      "[Parallel(n_jobs=6)]: Done 710 tasks      | elapsed:  3.2min\n",
      "[Parallel(n_jobs=6)]: Done 749 tasks      | elapsed:  3.3min\n",
      "[Parallel(n_jobs=6)]: Done 788 tasks      | elapsed:  3.5min\n",
      "[Parallel(n_jobs=6)]: Done 829 tasks      | elapsed:  3.7min\n",
      "[Parallel(n_jobs=6)]: Done 870 tasks      | elapsed:  3.9min\n",
      "[Parallel(n_jobs=6)]: Done 913 tasks      | elapsed:  4.1min\n",
      "[Parallel(n_jobs=6)]: Done 956 tasks      | elapsed:  4.4min\n",
      "[Parallel(n_jobs=6)]: Done 1001 tasks      | elapsed:  4.6min\n",
      "[Parallel(n_jobs=6)]: Done 1046 tasks      | elapsed:  4.8min\n",
      "[Parallel(n_jobs=6)]: Done 1093 tasks      | elapsed:  5.0min\n",
      "[Parallel(n_jobs=6)]: Done 1140 tasks      | elapsed:  5.3min\n",
      "[Parallel(n_jobs=6)]: Done 1189 tasks      | elapsed:  5.5min\n",
      "[Parallel(n_jobs=6)]: Done 1238 tasks      | elapsed:  5.8min\n",
      "[Parallel(n_jobs=6)]: Done 1289 tasks      | elapsed:  6.0min\n",
      "[Parallel(n_jobs=6)]: Done 1340 tasks      | elapsed:  6.3min\n",
      "[Parallel(n_jobs=6)]: Done 1393 tasks      | elapsed:  6.7min\n",
      "[Parallel(n_jobs=6)]: Done 1446 tasks      | elapsed:  6.9min\n",
      "[Parallel(n_jobs=6)]: Done 1501 tasks      | elapsed:  7.2min\n",
      "[Parallel(n_jobs=6)]: Done 1556 tasks      | elapsed:  7.5min\n",
      "[Parallel(n_jobs=6)]: Done 1613 tasks      | elapsed:  7.8min\n",
      "[Parallel(n_jobs=6)]: Done 1670 tasks      | elapsed:  8.1min\n",
      "[Parallel(n_jobs=6)]: Done 1729 tasks      | elapsed:  8.4min\n",
      "[Parallel(n_jobs=6)]: Done 1788 tasks      | elapsed:  8.8min\n",
      "[Parallel(n_jobs=6)]: Done 1800 out of 1800 | elapsed:  8.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best params\n",
      "{'max_depth': 2, 'min_samples_split': 7, 'n_estimators': 500}\n",
      "best score\n",
      "-0.3918457725449359\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "              'n_estimators': [50,100,200 ,500, 900],\n",
    "              'max_depth': range(1,10,1),\n",
    "              'min_samples_split': range(2,10,1)}\n",
    "\n",
    "gsearch = GridSearchCV(estimator = clf, param_grid = param_grid, n_jobs=6,iid=False, verbose=10,scoring='neg_mean_squared_error')\n",
    "\n",
    "gsearch.fit(X_RAND_train,y_RAND_train)\n",
    "\n",
    "print('best params')\n",
    "print (gsearch.best_params_)\n",
    "print('best score')\n",
    "print (gsearch.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 117 candidates, totalling 585 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done   1 tasks      | elapsed:    2.1s\n",
      "[Parallel(n_jobs=6)]: Done   6 tasks      | elapsed:    2.2s\n",
      "[Parallel(n_jobs=6)]: Done  13 tasks      | elapsed:    8.9s\n",
      "[Parallel(n_jobs=6)]: Done  20 tasks      | elapsed:   11.4s\n",
      "[Parallel(n_jobs=6)]: Done  29 tasks      | elapsed:   13.7s\n",
      "[Parallel(n_jobs=6)]: Done  38 tasks      | elapsed:   17.9s\n",
      "[Parallel(n_jobs=6)]: Done  49 tasks      | elapsed:   22.0s\n",
      "[Parallel(n_jobs=6)]: Done  60 tasks      | elapsed:   24.8s\n",
      "[Parallel(n_jobs=6)]: Done  73 tasks      | elapsed:   30.4s\n",
      "[Parallel(n_jobs=6)]: Done  86 tasks      | elapsed:   35.3s\n",
      "[Parallel(n_jobs=6)]: Done 101 tasks      | elapsed:   39.5s\n",
      "[Parallel(n_jobs=6)]: Done 116 tasks      | elapsed:   45.2s\n",
      "[Parallel(n_jobs=6)]: Done 133 tasks      | elapsed:   54.9s\n",
      "[Parallel(n_jobs=6)]: Done 150 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=6)]: Done 169 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=6)]: Done 188 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=6)]: Done 209 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=6)]: Done 230 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=6)]: Done 253 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=6)]: Done 276 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=6)]: Done 301 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=6)]: Done 326 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=6)]: Done 353 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=6)]: Done 380 tasks      | elapsed:  2.5min\n",
      "[Parallel(n_jobs=6)]: Done 409 tasks      | elapsed:  2.7min\n",
      "[Parallel(n_jobs=6)]: Done 438 tasks      | elapsed:  2.9min\n",
      "[Parallel(n_jobs=6)]: Done 469 tasks      | elapsed:  3.2min\n",
      "[Parallel(n_jobs=6)]: Done 500 tasks      | elapsed:  3.4min\n",
      "[Parallel(n_jobs=6)]: Done 533 tasks      | elapsed:  3.6min\n",
      "[Parallel(n_jobs=6)]: Done 566 tasks      | elapsed:  3.9min\n",
      "[Parallel(n_jobs=6)]: Done 585 out of 585 | elapsed:  4.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best params\n",
      "{'max_leaf_nodes': 3, 'min_samples_leaf': 5}\n",
      "best score\n",
      "-0.3777524890307898\n"
     ]
    }
   ],
   "source": [
    "# {'max_depth': 2, 'min_samples_split': 7, 'n_estimators': 500} \n",
    "param_grid = {\n",
    "              \"min_samples_leaf\": range(1,10,1),\n",
    "              \"max_leaf_nodes\": range(2,15,1)\n",
    "              }\n",
    "    \n",
    "clf = RandomForestRegressor(\n",
    "            criterion ='mse', \n",
    "            n_estimators = 500,\n",
    "            max_depth = 2,\n",
    "            min_samples_split = 7,\n",
    "            random_state = 42\n",
    ")\n",
    "\n",
    "gsearch = GridSearchCV(estimator = clf, param_grid = param_grid, n_jobs=6,iid=False, verbose=10,scoring='neg_mean_squared_error')\n",
    "\n",
    "gsearch.fit(X_RAND_train,y_RAND_train)\n",
    "\n",
    "print('best params')\n",
    "print (gsearch.best_params_)\n",
    "print('best score')\n",
    "print (gsearch.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_rmse_ave: 0.5992695000065618\n",
      "[0.42449305712875873, 0.6765634229439021, 0.8571850322298274, 0.46536364368303335, 0.6550714383674187, 0.6951032756058838, 0.7247560260997505, 0.6925960420160501, 0.4417597571020723, 0.359803304888921]\n",
      "\n",
      "\n",
      "test_r2_ave: 0.41013784632330685\n",
      "[0.6618425988269516, 0.3330035231537237, 0.35980188048584527, 0.3416565756421902, 0.5110722241981486, 0.3357802960066595, 0.28324468147231285, 0.14545049250183517, 0.5342537657333033, 0.5952724252120978]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rand_model = RandomForestRegressor( \n",
    "            criterion ='mse', \n",
    "            n_estimators = 500,\n",
    "            max_depth = 2,\n",
    "            min_samples_split = 7,\n",
    "            max_leaf_nodes = 3,\n",
    "            min_samples_leaf =5,\n",
    "            random_state = 42) \n",
    "rand_ave(skew_data[title], y,rand_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
