{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import MinMaxScaler, RobustScaler, StandardScaler\n",
    "from sklearn.linear_model import LinearRegression, LassoCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "import math\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from scipy import stats\n",
    "import matplotlib.style as style\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from scipy.stats import norm, skew #for some statistics\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "# èç data å¥ä»¶\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from xgboost.sklearn import XGBRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score,KFold\n",
    "from scipy.stats import skew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def skew_pro(data):\n",
    "    columns=data.drop(['Predict'], axis=1).columns\n",
    "    for col in columns: \n",
    "        if abs(data[col].skew()) >= 0.7: \n",
    "            pt = PowerTransformer() \n",
    "            d = pt.fit_transform(data[col].values.reshape(-1, 1)).flatten()\n",
    "            data[col]=d\n",
    "    X = data[columns]\n",
    "    scaler = RobustScaler()\n",
    "    data[columns] = scaler.fit_transform(X)\n",
    "    \n",
    "    return data\n",
    "\n",
    "def lr_rmse_ave(x,y):\n",
    "    \n",
    "    \n",
    "    train_rmse=[]\n",
    "    test_rmse=[]\n",
    "    test_r2=[]\n",
    "    \n",
    "    for i in np.arange(10):\n",
    "        x_train,x_test,y_train,y_test = train_test_split(x,y, random_state = i)\n",
    "        lr = LinearRegression().fit(x_train,y_train)\n",
    "\n",
    "        y_train_pred = lr.predict(x_train)\n",
    "        y_test_pred = lr.predict(x_test)\n",
    "        train_rmse.append(mean_squared_error(y_train, y_train_pred,squared=False))\n",
    "        test_rmse.append(mean_squared_error(y_test, y_test_pred,squared=False))\n",
    "        test_r2.append(r2_score(y_test,y_test_pred))\n",
    "    \n",
    "    train_rmse=np.array(train_rmse).mean()\n",
    "    test_rmse=np.array(test_rmse).mean()\n",
    "    test_r2=np.array(test_r2).mean()\n",
    "    \n",
    "#     print('train_rmse:', train_rmse)\n",
    "#     print('test_rmse:', test_rmse)\n",
    "#     print('test_r2:', test_r2)\n",
    "    return train_rmse, test_rmse, test_r2\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input_A3_013\n",
      "./BayesianRidge_Pre_0/\n",
      "feature number: 2\n",
      "train_rmse: 0.0014633161034438584\n",
      "test_rmse: 0.0014723010657973603\n",
      "test_r2: 0.19857732099877837\n",
      "feature number: 3\n",
      "train_rmse: 0.0014326004925003157\n",
      "test_rmse: 0.001451349065164711\n",
      "test_r2: 0.21740546749192763\n",
      "feature number: 4\n",
      "train_rmse: 0.0014027927656574996\n",
      "test_rmse: 0.0014317717871205956\n",
      "test_r2: 0.23819332642463786\n",
      "feature number: 5\n",
      "train_rmse: 0.001390545513971083\n",
      "test_rmse: 0.0014277455515734308\n",
      "test_r2: 0.24346557712638384\n",
      "feature number: 6\n",
      "train_rmse: 0.0013798295340172293\n",
      "test_rmse: 0.0014260865268315675\n",
      "test_r2: 0.24349209285691095\n",
      "feature number: 7\n",
      "train_rmse: 0.0013785975510688451\n",
      "test_rmse: 0.0014313350542259123\n",
      "test_r2: 0.23624049440115685\n",
      "feature number: 8\n",
      "train_rmse: 0.0013780261523848069\n",
      "test_rmse: 0.001433716921943052\n",
      "test_r2: 0.23364016483690314\n",
      "feature number: 9\n",
      "train_rmse: 0.0013611312986392334\n",
      "test_rmse: 0.001435150310138462\n",
      "test_r2: 0.23227705047042826\n",
      "feature number: 10\n",
      "train_rmse: 0.0013589010171208367\n",
      "test_rmse: 0.0014354644938873343\n",
      "test_r2: 0.23253139326929678\n",
      "feature number: 11\n",
      "train_rmse: 0.0013573912282108915\n",
      "test_rmse: 0.0014455039574147086\n",
      "test_r2: 0.22029826118374576\n",
      "feature number: 12\n",
      "train_rmse: 0.0013568051552153265\n",
      "test_rmse: 0.0014483635970923368\n",
      "test_r2: 0.2170749986078342\n",
      "feature number: 13\n",
      "train_rmse: 0.0013543451702746488\n",
      "test_rmse: 0.0014535746736002273\n",
      "test_r2: 0.21171240706709696\n",
      "feature number: 14\n",
      "train_rmse: 0.001351703190078452\n",
      "test_rmse: 0.001462770905553079\n",
      "test_r2: 0.20085187282178488\n",
      "feature number: 15\n",
      "train_rmse: 0.001351341476099318\n",
      "test_rmse: 0.0014652294818398722\n",
      "test_r2: 0.19828324010232173\n",
      "feature number: 16\n",
      "train_rmse: 0.001350673936743351\n",
      "test_rmse: 0.0014680004728212354\n",
      "test_r2: 0.1952704364190107\n",
      "feature number: 17\n",
      "train_rmse: 0.0013402760084799598\n",
      "test_rmse: 0.001466522517547138\n",
      "test_r2: 0.1958088269545318\n",
      "feature number: 18\n",
      "train_rmse: 0.001331415086357025\n",
      "test_rmse: 0.0014718622036072328\n",
      "test_r2: 0.18919425135592616\n",
      "feature number: 19\n",
      "train_rmse: 0.001323980833961265\n",
      "test_rmse: 0.001462909088528237\n",
      "test_r2: 0.19910103477578658\n",
      "feature number: 20\n",
      "train_rmse: 0.001314472144798303\n",
      "test_rmse: 0.0014725821191173358\n",
      "test_r2: 0.18908306763942764\n",
      "Test_rmse_min = 1.fea_num: 6  2.rmse: 0.0014260865268315675\n",
      "Test_r2_max = 1. fea_num: 6  2.r2: 0.24349209285691095\n",
      "./BayesianRidge_Pre_1/\n",
      "feature number: 2\n",
      "train_rmse: 0.0014633161034438584\n",
      "test_rmse: 0.0014723010657973603\n",
      "test_r2: 0.19857732099877837\n",
      "feature number: 3\n",
      "train_rmse: 0.0014326004925003157\n",
      "test_rmse: 0.001451349065164711\n",
      "test_r2: 0.21740546749192763\n",
      "feature number: 4\n",
      "train_rmse: 0.0014027927656574996\n",
      "test_rmse: 0.0014317717871205956\n",
      "test_r2: 0.23819332642463786\n",
      "feature number: 5\n",
      "train_rmse: 0.001390545513971083\n",
      "test_rmse: 0.0014277455515734308\n",
      "test_r2: 0.24346557712638384\n",
      "feature number: 6\n",
      "train_rmse: 0.0013798295340172293\n",
      "test_rmse: 0.0014260865268315675\n",
      "test_r2: 0.24349209285691095\n",
      "feature number: 7\n",
      "train_rmse: 0.001366182884562912\n",
      "test_rmse: 0.0014037982867130328\n",
      "test_r2: 0.26721159879824874\n",
      "feature number: 8\n",
      "train_rmse: 0.0013645056088834975\n",
      "test_rmse: 0.0014084771637673276\n",
      "test_r2: 0.26083255991145887\n",
      "feature number: 9\n",
      "train_rmse: 0.0013640531987973742\n",
      "test_rmse: 0.0014111525350296791\n",
      "test_r2: 0.25792091004022577\n",
      "feature number: 10\n",
      "train_rmse: 0.0013573164116204663\n",
      "test_rmse: 0.0014129661249084541\n",
      "test_r2: 0.25610472775184556\n",
      "feature number: 11\n",
      "train_rmse: 0.0013411323869744127\n",
      "test_rmse: 0.0014197755458984665\n",
      "test_r2: 0.24947371396181595\n",
      "feature number: 12\n",
      "train_rmse: 0.001339190660863195\n",
      "test_rmse: 0.0014205134613991754\n",
      "test_r2: 0.24924753878476585\n",
      "feature number: 13\n",
      "train_rmse: 0.0013371382144589795\n",
      "test_rmse: 0.0014294536809593722\n",
      "test_r2: 0.2381185020605403\n",
      "feature number: 14\n",
      "train_rmse: 0.0013353655672052104\n",
      "test_rmse: 0.0014436263549107956\n",
      "test_r2: 0.22162412220104954\n",
      "feature number: 15\n",
      "train_rmse: 0.001334737445158464\n",
      "test_rmse: 0.0014464895745527429\n",
      "test_r2: 0.2185176067322873\n",
      "feature number: 16\n",
      "train_rmse: 0.001332050308863564\n",
      "test_rmse: 0.0014576101222509982\n",
      "test_r2: 0.2044449251535553\n",
      "feature number: 17\n",
      "train_rmse: 0.001330108311079849\n",
      "test_rmse: 0.0014679045302612031\n",
      "test_r2: 0.19065833046765954\n",
      "feature number: 18\n",
      "train_rmse: 0.0013285592399212682\n",
      "test_rmse: 0.001475868483405962\n",
      "test_r2: 0.18246467764089985\n",
      "feature number: 19\n",
      "train_rmse: 0.001319616636833111\n",
      "test_rmse: 0.0014670766877226576\n",
      "test_r2: 0.19417934852871954\n",
      "feature number: 20\n",
      "train_rmse: 0.0013132493609624403\n",
      "test_rmse: 0.0014673756933077462\n",
      "test_r2: 0.19029049540372484\n",
      "Test_rmse_min = 1.fea_num: 7  2.rmse: 0.0014037982867130328\n",
      "Test_r2_max = 1. fea_num: 7  2.r2: 0.26721159879824874\n",
      "./BayesianRidge_Pre_2/\n",
      "feature number: 2\n",
      "train_rmse: 0.0014633161034438584\n",
      "test_rmse: 0.0014723010657973603\n",
      "test_r2: 0.19857732099877837\n",
      "feature number: 3\n",
      "train_rmse: 0.0014326004925003157\n",
      "test_rmse: 0.001451349065164711\n",
      "test_r2: 0.21740546749192763\n",
      "feature number: 4\n",
      "train_rmse: 0.0014027927656574996\n",
      "test_rmse: 0.0014317717871205956\n",
      "test_r2: 0.23819332642463786\n",
      "feature number: 5\n",
      "train_rmse: 0.001390545513971083\n",
      "test_rmse: 0.0014277455515734308\n",
      "test_r2: 0.24346557712638384\n",
      "feature number: 6\n",
      "train_rmse: 0.0013798295340172293\n",
      "test_rmse: 0.0014260865268315675\n",
      "test_r2: 0.24349209285691095\n",
      "feature number: 7\n",
      "train_rmse: 0.001366182884562912\n",
      "test_rmse: 0.0014037982867130328\n",
      "test_r2: 0.26721159879824874\n",
      "feature number: 8\n",
      "train_rmse: 0.0013645056088834975\n",
      "test_rmse: 0.0014084771637673276\n",
      "test_r2: 0.26083255991145887\n",
      "feature number: 9\n",
      "train_rmse: 0.0013640531987973742\n",
      "test_rmse: 0.0014111525350296791\n",
      "test_r2: 0.25792091004022577\n",
      "feature number: 10\n",
      "train_rmse: 0.0013573164116204663\n",
      "test_rmse: 0.0014129661249084541\n",
      "test_r2: 0.25610472775184556\n",
      "feature number: 11\n",
      "train_rmse: 0.0013411323869744127\n",
      "test_rmse: 0.0014197755458984665\n",
      "test_r2: 0.24947371396181595\n",
      "feature number: 12\n",
      "train_rmse: 0.001339190660863195\n",
      "test_rmse: 0.0014205134613991754\n",
      "test_r2: 0.24924753878476585\n",
      "feature number: 13\n",
      "train_rmse: 0.0013371382144589795\n",
      "test_rmse: 0.0014294536809593722\n",
      "test_r2: 0.2381185020605403\n",
      "feature number: 14\n",
      "train_rmse: 0.0013353655672052104\n",
      "test_rmse: 0.0014436263549107956\n",
      "test_r2: 0.22162412220104954\n",
      "feature number: 15\n",
      "train_rmse: 0.001334737445158464\n",
      "test_rmse: 0.0014464895745527429\n",
      "test_r2: 0.2185176067322873\n",
      "feature number: 16\n",
      "train_rmse: 0.001332050308863564\n",
      "test_rmse: 0.0014576101222509982\n",
      "test_r2: 0.2044449251535553\n",
      "feature number: 17\n",
      "train_rmse: 0.001330108311079849\n",
      "test_rmse: 0.0014679045302612031\n",
      "test_r2: 0.19065833046765954\n",
      "feature number: 18\n",
      "train_rmse: 0.0013285575025501002\n",
      "test_rmse: 0.0014758671944191028\n",
      "test_r2: 0.18246729810613108\n",
      "feature number: 19\n",
      "train_rmse: 0.0013196136849993577\n",
      "test_rmse: 0.0014670734462690189\n",
      "test_r2: 0.19418411312835\n",
      "feature number: 20\n",
      "train_rmse: 0.0013132463482451097\n",
      "test_rmse: 0.001467372503643634\n",
      "test_r2: 0.19029526236522773\n",
      "Test_rmse_min = 1.fea_num: 7  2.rmse: 0.0014037982867130328\n",
      "Test_r2_max = 1. fea_num: 7  2.r2: 0.26721159879824874\n",
      "./BayesianRidge_Pre_3/\n",
      "feature number: 2\n",
      "train_rmse: 0.0014633161034438584\n",
      "test_rmse: 0.0014723010657973603\n",
      "test_r2: 0.19857732099877837\n",
      "feature number: 3\n",
      "train_rmse: 0.0014326004925003157\n",
      "test_rmse: 0.001451349065164711\n",
      "test_r2: 0.21740546749192763\n",
      "feature number: 4\n",
      "train_rmse: 0.0014027927656574996\n",
      "test_rmse: 0.0014317717871205956\n",
      "test_r2: 0.23819332642463786\n",
      "feature number: 5\n",
      "train_rmse: 0.001390545513971083\n",
      "test_rmse: 0.0014277455515734308\n",
      "test_r2: 0.24346557712638384\n",
      "feature number: 6\n",
      "train_rmse: 0.0013798295340172293\n",
      "test_rmse: 0.0014260865268315675\n",
      "test_r2: 0.24349209285691095\n",
      "feature number: 7\n",
      "train_rmse: 0.001366182884562912\n",
      "test_rmse: 0.0014037982867130328\n",
      "test_r2: 0.26721159879824874\n",
      "feature number: 8\n",
      "train_rmse: 0.0013645056088834975\n",
      "test_rmse: 0.0014084771637673276\n",
      "test_r2: 0.26083255991145887\n",
      "feature number: 9\n",
      "train_rmse: 0.0013640531987973742\n",
      "test_rmse: 0.0014111525350296791\n",
      "test_r2: 0.25792091004022577\n",
      "feature number: 10\n",
      "train_rmse: 0.0013573164116204663\n",
      "test_rmse: 0.0014129661249084541\n",
      "test_r2: 0.25610472775184556\n",
      "feature number: 11\n",
      "train_rmse: 0.0013411323869744127\n",
      "test_rmse: 0.0014197755458984665\n",
      "test_r2: 0.24947371396181595\n",
      "feature number: 12\n",
      "train_rmse: 0.001339190660863195\n",
      "test_rmse: 0.0014205134613991754\n",
      "test_r2: 0.24924753878476585\n",
      "feature number: 13\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_rmse: 0.0013371382144589795\n",
      "test_rmse: 0.0014294536809593722\n",
      "test_r2: 0.2381185020605403\n",
      "feature number: 14\n",
      "train_rmse: 0.0013353655672052104\n",
      "test_rmse: 0.0014436263549107956\n",
      "test_r2: 0.22162412220104954\n",
      "feature number: 15\n",
      "train_rmse: 0.001334737445158464\n",
      "test_rmse: 0.0014464895745527429\n",
      "test_r2: 0.2185176067322873\n",
      "feature number: 16\n",
      "train_rmse: 0.001332050308863564\n",
      "test_rmse: 0.0014576101222509982\n",
      "test_r2: 0.2044449251535553\n",
      "feature number: 17\n",
      "train_rmse: 0.001330108311079849\n",
      "test_rmse: 0.0014679045302612031\n",
      "test_r2: 0.19065833046765954\n",
      "feature number: 18\n",
      "train_rmse: 0.0013285749183062536\n",
      "test_rmse: 0.0014758690293844884\n",
      "test_r2: 0.1824533758634721\n",
      "feature number: 19\n",
      "train_rmse: 0.0013196426425039571\n",
      "test_rmse: 0.0014670977883806985\n",
      "test_r2: 0.1941449347304045\n",
      "feature number: 20\n",
      "train_rmse: 0.0013132754407153063\n",
      "test_rmse: 0.0014673958417874707\n",
      "test_r2: 0.1902564183085315\n",
      "Test_rmse_min = 1.fea_num: 7  2.rmse: 0.0014037982867130328\n",
      "Test_r2_max = 1. fea_num: 7  2.r2: 0.26721159879824874\n",
      "./BayesianRidge_Pre_4/\n",
      "feature number: 2\n",
      "train_rmse: 0.0014633161034438584\n",
      "test_rmse: 0.0014723010657973603\n",
      "test_r2: 0.19857732099877837\n",
      "feature number: 3\n",
      "train_rmse: 0.0014326004925003157\n",
      "test_rmse: 0.001451349065164711\n",
      "test_r2: 0.21740546749192763\n",
      "feature number: 4\n",
      "train_rmse: 0.0014027927656574996\n",
      "test_rmse: 0.0014317717871205956\n",
      "test_r2: 0.23819332642463786\n",
      "feature number: 5\n",
      "train_rmse: 0.001390545513971083\n",
      "test_rmse: 0.0014277455515734308\n",
      "test_r2: 0.24346557712638384\n",
      "feature number: 6\n",
      "train_rmse: 0.0013798295340172293\n",
      "test_rmse: 0.0014260865268315675\n",
      "test_r2: 0.24349209285691095\n",
      "feature number: 7\n",
      "train_rmse: 0.001366182884562912\n",
      "test_rmse: 0.0014037982867130328\n",
      "test_r2: 0.26721159879824874\n",
      "feature number: 8\n",
      "train_rmse: 0.0013645056088834975\n",
      "test_rmse: 0.0014084771637673276\n",
      "test_r2: 0.26083255991145887\n",
      "feature number: 9\n",
      "train_rmse: 0.0013640531987973742\n",
      "test_rmse: 0.0014111525350296791\n",
      "test_r2: 0.25792091004022577\n",
      "feature number: 10\n",
      "train_rmse: 0.0013573164116204663\n",
      "test_rmse: 0.0014129661249084541\n",
      "test_r2: 0.25610472775184556\n",
      "feature number: 11\n",
      "train_rmse: 0.0013411323869744127\n",
      "test_rmse: 0.0014197755458984665\n",
      "test_r2: 0.24947371396181595\n",
      "feature number: 12\n",
      "train_rmse: 0.001339190660863195\n",
      "test_rmse: 0.0014205134613991754\n",
      "test_r2: 0.24924753878476585\n",
      "feature number: 13\n",
      "train_rmse: 0.0013371382144589795\n",
      "test_rmse: 0.0014294536809593722\n",
      "test_r2: 0.2381185020605403\n",
      "feature number: 14\n",
      "train_rmse: 0.0013353655672052104\n",
      "test_rmse: 0.0014436263549107956\n",
      "test_r2: 0.22162412220104954\n",
      "feature number: 15\n",
      "train_rmse: 0.001334737445158464\n",
      "test_rmse: 0.0014464895745527429\n",
      "test_r2: 0.2185176067322873\n",
      "feature number: 16\n",
      "train_rmse: 0.001332050308863564\n",
      "test_rmse: 0.0014576101222509982\n",
      "test_r2: 0.2044449251535553\n",
      "feature number: 17\n",
      "train_rmse: 0.001330108311079849\n",
      "test_rmse: 0.0014679045302612031\n",
      "test_r2: 0.19065833046765954\n",
      "feature number: 18\n",
      "train_rmse: 0.0013285610354825746\n",
      "test_rmse: 0.0014758551453679463\n",
      "test_r2: 0.18247955681923975\n",
      "feature number: 19\n",
      "train_rmse: 0.0013196173707434946\n",
      "test_rmse: 0.0014670651832610292\n",
      "test_r2: 0.19419159140471093\n",
      "feature number: 20\n",
      "train_rmse: 0.0013132493498487772\n",
      "test_rmse: 0.001467364612683754\n",
      "test_r2: 0.19030198821025315\n",
      "Test_rmse_min = 1.fea_num: 7  2.rmse: 0.0014037982867130328\n",
      "Test_r2_max = 1. fea_num: 7  2.r2: 0.26721159879824874\n",
      "./BayesianRidge_Pre_5/\n",
      "feature number: 2\n",
      "train_rmse: 0.0014633161034438584\n",
      "test_rmse: 0.0014723010657973603\n",
      "test_r2: 0.19857732099877837\n",
      "feature number: 3\n",
      "train_rmse: 0.0014326004925003157\n",
      "test_rmse: 0.001451349065164711\n",
      "test_r2: 0.21740546749192763\n",
      "feature number: 4\n",
      "train_rmse: 0.0014027927656574996\n",
      "test_rmse: 0.0014317717871205956\n",
      "test_r2: 0.23819332642463786\n",
      "feature number: 5\n",
      "train_rmse: 0.001390545513971083\n",
      "test_rmse: 0.0014277455515734308\n",
      "test_r2: 0.24346557712638384\n",
      "feature number: 6\n",
      "train_rmse: 0.0013798295340172293\n",
      "test_rmse: 0.0014260865268315675\n",
      "test_r2: 0.24349209285691095\n",
      "feature number: 7\n",
      "train_rmse: 0.001366182884562912\n",
      "test_rmse: 0.0014037982867130328\n",
      "test_r2: 0.26721159879824874\n",
      "feature number: 8\n",
      "train_rmse: 0.0013645056088834975\n",
      "test_rmse: 0.0014084771637673276\n",
      "test_r2: 0.26083255991145887\n",
      "feature number: 9\n",
      "train_rmse: 0.0013640531987973742\n",
      "test_rmse: 0.0014111525350296791\n",
      "test_r2: 0.25792091004022577\n",
      "feature number: 10\n",
      "train_rmse: 0.0013573164116204663\n",
      "test_rmse: 0.0014129661249084541\n",
      "test_r2: 0.25610472775184556\n",
      "feature number: 11\n",
      "train_rmse: 0.0013411323869744127\n",
      "test_rmse: 0.0014197755458984665\n",
      "test_r2: 0.24947371396181595\n",
      "feature number: 12\n",
      "train_rmse: 0.001339190660863195\n",
      "test_rmse: 0.0014205134613991754\n",
      "test_r2: 0.24924753878476585\n",
      "feature number: 13\n",
      "train_rmse: 0.0013371382144589795\n",
      "test_rmse: 0.0014294536809593722\n",
      "test_r2: 0.2381185020605403\n",
      "feature number: 14\n",
      "train_rmse: 0.0013353655672052104\n",
      "test_rmse: 0.0014436263549107956\n",
      "test_r2: 0.22162412220104954\n",
      "feature number: 15\n",
      "train_rmse: 0.001334737445158464\n",
      "test_rmse: 0.0014464895745527429\n",
      "test_r2: 0.2185176067322873\n",
      "feature number: 16\n",
      "train_rmse: 0.001332050308863564\n",
      "test_rmse: 0.0014576101222509982\n",
      "test_r2: 0.2044449251535553\n",
      "feature number: 17\n",
      "train_rmse: 0.001330108311079849\n",
      "test_rmse: 0.0014679045302612031\n",
      "test_r2: 0.19065833046765954\n",
      "feature number: 18\n",
      "train_rmse: 0.0013285767924142654\n",
      "test_rmse: 0.00147585571231017\n",
      "test_r2: 0.18246819089324168\n",
      "feature number: 19\n",
      "train_rmse: 0.0013196435274869956\n",
      "test_rmse: 0.0014670864411070006\n",
      "test_r2: 0.19415696234742033\n",
      "feature number: 20\n",
      "train_rmse: 0.0013132755965983857\n",
      "test_rmse: 0.0014673849293644244\n",
      "test_r2: 0.19026768079989415\n",
      "Test_rmse_min = 1.fea_num: 7  2.rmse: 0.0014037982867130328\n",
      "Test_r2_max = 1. fea_num: 7  2.r2: 0.26721159879824874\n",
      "./BayesianRidge_Pre_6/\n",
      "feature number: 2\n",
      "train_rmse: 0.0014633161034438584\n",
      "test_rmse: 0.0014723010657973603\n",
      "test_r2: 0.19857732099877837\n",
      "feature number: 3\n",
      "train_rmse: 0.0014326004925003157\n",
      "test_rmse: 0.001451349065164711\n",
      "test_r2: 0.21740546749192763\n",
      "feature number: 4\n",
      "train_rmse: 0.0014027927656574996\n",
      "test_rmse: 0.0014317717871205956\n",
      "test_r2: 0.23819332642463786\n",
      "feature number: 5\n",
      "train_rmse: 0.001390545513971083\n",
      "test_rmse: 0.0014277455515734308\n",
      "test_r2: 0.24346557712638384\n",
      "feature number: 6\n",
      "train_rmse: 0.0013798295340172293\n",
      "test_rmse: 0.0014260865268315675\n",
      "test_r2: 0.24349209285691095\n",
      "feature number: 7\n",
      "train_rmse: 0.001366182884562912\n",
      "test_rmse: 0.0014037982867130328\n",
      "test_r2: 0.26721159879824874\n",
      "feature number: 8\n",
      "train_rmse: 0.0013645056088834975\n",
      "test_rmse: 0.0014084771637673276\n",
      "test_r2: 0.26083255991145887\n",
      "feature number: 9\n",
      "train_rmse: 0.0013640531987973742\n",
      "test_rmse: 0.0014111525350296791\n",
      "test_r2: 0.25792091004022577\n",
      "feature number: 10\n",
      "train_rmse: 0.0013573164116204663\n",
      "test_rmse: 0.0014129661249084541\n",
      "test_r2: 0.25610472775184556\n",
      "feature number: 11\n",
      "train_rmse: 0.0013411323869744127\n",
      "test_rmse: 0.0014197755458984665\n",
      "test_r2: 0.24947371396181595\n",
      "feature number: 12\n",
      "train_rmse: 0.001339190660863195\n",
      "test_rmse: 0.0014205134613991754\n",
      "test_r2: 0.24924753878476585\n",
      "feature number: 13\n",
      "train_rmse: 0.0013371382144589795\n",
      "test_rmse: 0.0014294536809593722\n",
      "test_r2: 0.2381185020605403\n",
      "feature number: 14\n",
      "train_rmse: 0.0013353655672052104\n",
      "test_rmse: 0.0014436263549107956\n",
      "test_r2: 0.22162412220104954\n",
      "feature number: 15\n",
      "train_rmse: 0.001334737445158464\n",
      "test_rmse: 0.0014464895745527429\n",
      "test_r2: 0.2185176067322873\n",
      "feature number: 16\n",
      "train_rmse: 0.001332050308863564\n",
      "test_rmse: 0.0014576101222509982\n",
      "test_r2: 0.2044449251535553\n",
      "feature number: 17\n",
      "train_rmse: 0.001330108311079849\n",
      "test_rmse: 0.0014679045302612031\n",
      "test_r2: 0.19065833046765954\n",
      "feature number: 18\n",
      "train_rmse: 0.0013217941715244173\n",
      "test_rmse: 0.0014595126141020262\n",
      "test_r2: 0.20154951700322016\n",
      "feature number: 19\n",
      "train_rmse: 0.0013153442617101804\n",
      "test_rmse: 0.0014599784648442148\n",
      "test_r2: 0.19745395933827806\n",
      "feature number: 20\n",
      "train_rmse: 0.0013134541152721706\n",
      "test_rmse: 0.0014715587442940654\n",
      "test_r2: 0.18312502890960253\n",
      "Test_rmse_min = 1.fea_num: 7  2.rmse: 0.0014037982867130328\n",
      "Test_r2_max = 1. fea_num: 7  2.r2: 0.26721159879824874\n",
      "./BayesianRidge_Pre_7/\n",
      "feature number: 2\n",
      "train_rmse: 0.0014633161034438584\n",
      "test_rmse: 0.0014723010657973603\n",
      "test_r2: 0.19857732099877837\n",
      "feature number: 3\n",
      "train_rmse: 0.0014326004925003157\n",
      "test_rmse: 0.001451349065164711\n",
      "test_r2: 0.21740546749192763\n",
      "feature number: 4\n",
      "train_rmse: 0.0014027927656574996\n",
      "test_rmse: 0.0014317717871205956\n",
      "test_r2: 0.23819332642463786\n",
      "feature number: 5\n",
      "train_rmse: 0.001390545513971083\n",
      "test_rmse: 0.0014277455515734308\n",
      "test_r2: 0.24346557712638384\n",
      "feature number: 6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_rmse: 0.0013798295340172293\n",
      "test_rmse: 0.0014260865268315675\n",
      "test_r2: 0.24349209285691095\n",
      "feature number: 7\n",
      "train_rmse: 0.001366182884562912\n",
      "test_rmse: 0.0014037982867130328\n",
      "test_r2: 0.26721159879824874\n",
      "feature number: 8\n",
      "train_rmse: 0.0013645056088834975\n",
      "test_rmse: 0.0014084771637673276\n",
      "test_r2: 0.26083255991145887\n",
      "feature number: 9\n",
      "train_rmse: 0.0013640531987973742\n",
      "test_rmse: 0.0014111525350296791\n",
      "test_r2: 0.25792091004022577\n",
      "feature number: 10\n",
      "train_rmse: 0.0013573164116204663\n",
      "test_rmse: 0.0014129661249084541\n",
      "test_r2: 0.25610472775184556\n",
      "feature number: 11\n",
      "train_rmse: 0.0013411323869744127\n",
      "test_rmse: 0.0014197755458984665\n",
      "test_r2: 0.24947371396181595\n",
      "feature number: 12\n",
      "train_rmse: 0.001339190660863195\n",
      "test_rmse: 0.0014205134613991754\n",
      "test_r2: 0.24924753878476585\n",
      "feature number: 13\n",
      "train_rmse: 0.0013371382144589795\n",
      "test_rmse: 0.0014294536809593722\n",
      "test_r2: 0.2381185020605403\n",
      "feature number: 14\n",
      "train_rmse: 0.0013353655672052104\n",
      "test_rmse: 0.0014436263549107956\n",
      "test_r2: 0.22162412220104954\n",
      "feature number: 15\n",
      "train_rmse: 0.001334737445158464\n",
      "test_rmse: 0.0014464895745527429\n",
      "test_r2: 0.2185176067322873\n",
      "feature number: 16\n",
      "train_rmse: 0.0013334742769394068\n",
      "test_rmse: 0.0014534263276374509\n",
      "test_r2: 0.2114233011628635\n",
      "feature number: 17\n",
      "train_rmse: 0.0013304468007344682\n",
      "test_rmse: 0.0014656073193950957\n",
      "test_r2: 0.19621669028499863\n",
      "feature number: 18\n",
      "train_rmse: 0.0013284958264958436\n",
      "test_rmse: 0.0014758666724468896\n",
      "test_r2: 0.18254779819170106\n",
      "feature number: 19\n",
      "train_rmse: 0.0013195126612129751\n",
      "test_rmse: 0.0014669867277715236\n",
      "test_r2: 0.19436073521801162\n",
      "feature number: 20\n",
      "train_rmse: 0.0013131401758139855\n",
      "test_rmse: 0.0014673013614234073\n",
      "test_r2: 0.19046020414963266\n",
      "Test_rmse_min = 1.fea_num: 7  2.rmse: 0.0014037982867130328\n",
      "Test_r2_max = 1. fea_num: 7  2.r2: 0.26721159879824874\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "n='Input_A3_013'  #æ¹è·¯å¾\n",
    "#\n",
    "dire= ['./BayesianRidge_Pre_0/','./BayesianRidge_Pre_1/','./BayesianRidge_Pre_2/','./BayesianRidge_Pre_3/','./BayesianRidge_Pre_4/','./BayesianRidge_Pre_5/','./BayesianRidge_Pre_6/','./BayesianRidge_Pre_7/']\n",
    "# dire= ['../BayesianRidge_Pre_0/']\n",
    "print(n)\n",
    "for d in dire:\n",
    "    f_train_rmse=[]\n",
    "    f_test_rmse=[]\n",
    "    f_test_r2=[]\n",
    "    print(d)\n",
    "    data_d= d+n+'.csv'\n",
    "    data= pd.read_csv(data_d,index_col=0).drop(['Number'], axis=1)\n",
    "    y=data.Predict\n",
    "    skew_data=skew_pro(data)\n",
    "    num=skew_data.select_dtypes(exclude='object')\n",
    "    numcorr=num.corr()\n",
    "    f20=abs(numcorr['Predict']).sort_values(ascending=False).head(21).to_frame().index.to_numpy()[1:]\n",
    "    fea_list=[2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20]\n",
    "    for i in fea_list:\n",
    "        print('feature number:',i)\n",
    "        x=skew_data[f20[:i]]\n",
    "        tr_r,te_r, te_r2= lr_rmse_ave(x,y)\n",
    "        print('train_rmse:',tr_r)\n",
    "        print('test_rmse:',te_r)\n",
    "        print('test_r2:',te_r2)\n",
    "        f_train_rmse.append(tr_r)\n",
    "        f_test_rmse.append(te_r)\n",
    "        f_test_r2.append(te_r2)\n",
    "\n",
    "    test_r=np.array(f_test_rmse)\n",
    "    test_r2=np.array(f_test_r2)\n",
    "    test_r_min= np.where(test_r == np.amin(test_r))\n",
    "    test_r2_max= np.where(test_r2 == np.amax(test_r2))    \n",
    "    print('Test_rmse_min = 1.fea_num:', fea_list[test_r_min[0][0]], ' 2.rmse:' ,np.amin(test_r))\n",
    "    print('Test_r2_max = 1. fea_num:', fea_list[test_r2_max[0][0]],  ' 2.r2:', np.amax(test_r2))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Input_A1_013', 'Input_A6_014', 'Input_A1_014', 'Input_A2_013',\n",
       "       'Input_A6_013', 'Input_A5_014'], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fea_number=6\n",
    "#\n",
    "data=pd.read_csv('./BayesianRidge_Pre_0/Input_A3_013.csv',index_col=0).drop(['Number'], axis=1) ## æ¹è·¯å¾\n",
    "#\n",
    "y=data.Predict\n",
    "skew_data=skew_pro(data)\n",
    "\n",
    "num=skew_data.select_dtypes(exclude='object')\n",
    "numcorr=num.corr()\n",
    "title=abs(numcorr['Predict']).sort_values(ascending=False).head(fea_number+1).to_frame().index.to_numpy()[1:]\n",
    "skew_x=skew_data.drop(['Predict'], axis=1)\n",
    "title"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lr_rmse_ave_fea(data,fea_num):\n",
    "    \n",
    "    num=data.select_dtypes(exclude='object')\n",
    "    numcorr=num.corr()\n",
    "    cols=abs(numcorr['Predict']).sort_values(ascending=False).head(fea_num+1).to_frame().index.to_numpy()[1:]\n",
    "    y = data['Predict']\n",
    "    X= data[cols]\n",
    "    train_rmse=[]\n",
    "    test_rmse=[]\n",
    "    test_r2=[]\n",
    "    \n",
    "    for i in np.arange(10):\n",
    "        x_train,x_test,y_train,y_test = train_test_split(X,y, random_state = i)\n",
    "        lr = LinearRegression().fit(x_train,y_train)\n",
    "\n",
    "        y_train_pred = lr.predict(x_train)\n",
    "        y_test_pred = lr.predict(x_test)\n",
    "        train_rmse.append(mean_squared_error(y_train, y_train_pred,squared=False))\n",
    "        test_rmse.append(mean_squared_error(y_test, y_test_pred,squared=False))\n",
    "        test_r2.append(r2_score(y_test,y_test_pred))\n",
    "    \n",
    "    train_rmse=np.array(train_rmse).mean()\n",
    "    test_rmse=np.array(test_rmse).mean()\n",
    "    test_r2=np.array(test_r2).mean()\n",
    "    \n",
    "    print('train_rmse:', train_rmse)\n",
    "    print('test_rmse:', test_rmse)\n",
    "    print('test_r2:', test_r2)\n",
    "#     return train_rmse, test_rmse, test_r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_rmse: 0.0013798295340172293\n",
      "test_rmse: 0.0014260865268315675\n",
      "test_r2: 0.24349209285691095\n"
     ]
    }
   ],
   "source": [
    "lr_rmse_ave_fea(skew_data,6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def laso_alpha(x,y,parameters):\n",
    "    from sklearn.linear_model import Lasso\n",
    "    \n",
    "    para=[]\n",
    "\n",
    "    for i in np.arange(10):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=i)\n",
    "        lasso=Lasso()\n",
    "        lasso_reg=GridSearchCV(lasso, param_grid=parameters, scoring='neg_mean_squared_error', cv=3)\n",
    "        lasso_reg.fit(X_train,y_train)\n",
    "        para.append(lasso_reg.best_params_)\n",
    "\n",
    "    print(para)\n",
    "    \n",
    "def laso_rmse_ave(x,y,alp):\n",
    "    from sklearn.linear_model import Lasso\n",
    "    \n",
    "    rmse=[]\n",
    "    r2=[]\n",
    "\n",
    "    for i in np.arange(10):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=i)\n",
    "        lasso_mod=Lasso(alpha=alp)\n",
    "        lasso_mod.fit(X_train,y_train)\n",
    "        y_lasso_train=lasso_mod.predict(X_train)\n",
    "        y_lasso_test=lasso_mod.predict(X_test)\n",
    "        rmse.append(math.sqrt(mean_squared_error(y_test, y_lasso_test)))\n",
    "        r2.append(r2_score(y_test, y_lasso_test))\n",
    "    \n",
    "    test_rmse=np.array(rmse).mean()\n",
    "    print('test_rmse_ave:',test_rmse)\n",
    "    print(rmse)\n",
    "    print('\\n')\n",
    "    test_r2=np.array(r2).mean()\n",
    "    print('test_r2_ave:',test_r2)\n",
    "    print(r2)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'alpha': 9e-05}, {'alpha': 9e-05}, {'alpha': 9e-05}, {'alpha': 9e-05}, {'alpha': 9e-05}, {'alpha': 9e-05}, {'alpha': 9e-05}, {'alpha': 9e-05}, {'alpha': 9e-05}, {'alpha': 9e-05}]\n"
     ]
    }
   ],
   "source": [
    "parameters= {'alpha':[0.003,0.001,0.0009,0.00009,9e-06]}\n",
    "laso_alpha(skew_x,y,parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_rmse_ave: 0.0015038575701130006\n",
      "[0.001411074887946478, 0.0015814148181271296, 0.0015820481500048351, 0.0012094063891519681, 0.001282996352506465, 0.001563611832642493, 0.001513521082166165, 0.0017255849060805572, 0.0014410666876935928, 0.0017278505948103247]\n",
      "\n",
      "\n",
      "test_r2_ave: 0.18542392706768654\n",
      "[0.14633402195935674, 0.2877076928469482, 0.20569338667258863, 0.1285198578312441, 0.23065716914632062, 0.13339687358361407, 0.30264315828832933, 0.08558209992128851, 0.1601437213549941, 0.17356128907218094]\n"
     ]
    }
   ],
   "source": [
    "laso_rmse_ave(skew_x,y,9e-05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'alpha': 9e-06}, {'alpha': 9e-07}, {'alpha': 9e-07}, {'alpha': 9e-07}, {'alpha': 9e-06}, {'alpha': 9e-07}, {'alpha': 9e-07}, {'alpha': 9e-07}, {'alpha': 9e-07}, {'alpha': 9e-07}]\n"
     ]
    }
   ],
   "source": [
    "parameters= {'alpha':[0.003,0.001,0.0009,0.00009,9e-06,9e-07]}\n",
    "laso_alpha(skew_data[title],y,parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_rmse_ave: 0.0014508749359871344\n",
      "[0.0013068012180729913, 0.0014739764515110743, 0.0014213300502428667, 0.001236427000591078, 0.0012581921466134135, 0.0015507169204870906, 0.0014816229952249195, 0.0017012416972292613, 0.0014150304367976012, 0.001663410443101048]\n",
      "\n",
      "\n",
      "test_r2_ave: 0.23720160159406442\n",
      "[0.26783846570744907, 0.3812036596091042, 0.3588809813831213, 0.08914354740099883, 0.26011706970446613, 0.1476314713052419, 0.3317275826355379, 0.11119991033352095, 0.1902175163740768, 0.23405581148712706]\n"
     ]
    }
   ],
   "source": [
    "laso_rmse_ave(skew_data[title],y,5e-06)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ElasticNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score(y_pred):\n",
    "    return str(math.sqrt(mean_squared_error(y_test, y_pred)))\n",
    "\n",
    "def ElasticNet_alpha(x,y,alphas,l1ratio):\n",
    "    from sklearn.linear_model import ElasticNetCV\n",
    "    \n",
    "    alpha_=[]\n",
    "    l1_ratio_=[]\n",
    "\n",
    "    for i in np.arange(10):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=i)\n",
    "        elastic_cv = ElasticNetCV(cv=3, max_iter=1e7, alphas=alphas,  l1_ratio=l1ratio)\n",
    "        elasticmod = elastic_cv.fit(X_train, y_train.ravel())\n",
    "\n",
    "        alpha_.append(elastic_cv.alpha_)\n",
    "        l1_ratio_.append(elastic_cv.l1_ratio_)\n",
    "\n",
    "    print('alpha')\n",
    "    print(alpha_)\n",
    "    print('\\n')\n",
    "    print('l1_ratio')\n",
    "    print(l1_ratio_)\n",
    "    \n",
    "def ElasticNet_rmse_ave(x,y,alp,l1r):\n",
    "    from sklearn.linear_model import ElasticNet\n",
    "    \n",
    "    rmse=[]\n",
    "    r2=[]\n",
    "\n",
    "    for i in np.arange(10):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=i)\n",
    "        ElasticNet_mod=ElasticNet(alpha=alp, l1_ratio=l1r)\n",
    "        ElasticNet_mod.fit(X_train,y_train)\n",
    "        y_ElasticNet_train=ElasticNet_mod.predict(X_train)\n",
    "        y_ElasticNet_test=ElasticNet_mod.predict(X_test)\n",
    "        rmse.append(math.sqrt(mean_squared_error(y_test, y_ElasticNet_test)))\n",
    "        r2.append(r2_score(y_test, y_ElasticNet_test))\n",
    "    \n",
    "    test_rmse=np.array(rmse).mean()\n",
    "    print('test_rmse_ave:',test_rmse)\n",
    "    print(rmse)\n",
    "    print('\\n')\n",
    "    test_r2=np.array(r2).mean()\n",
    "    print('test_r2_ave:',test_r2)\n",
    "    print(r2)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha\n",
      "[0.008, 0.008, 0.008, 0.008, 0.008, 0.008, 0.008, 0.008, 0.008, 0.008]\n",
      "\n",
      "\n",
      "l1_ratio\n",
      "[0.02, 0.01, 0.01, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.01]\n"
     ]
    }
   ],
   "source": [
    "alphas = [0.008]\n",
    "\n",
    "# alphas =[0.07,0.06,0.05,0.04, 0.03,0.02,0.01,0.005,0]\n",
    "l1ratio = [0.02,0.01,0.03,0.04,0.06,0.07]\n",
    "ElasticNet_alpha(skew_x,y,alphas,l1ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_rmse_ave: 0.0015200920321475648\n",
      "[0.0013903273559837984, 0.0016294536654055671, 0.0015839724951200941, 0.0011808777965714886, 0.0013121493011550923, 0.001574222328060258, 0.001604876903745933, 0.0017352966080256963, 0.001450407389084724, 0.0017393364783229975]\n",
      "\n",
      "\n",
      "test_r2_ave: 0.17077669902157688\n",
      "[0.17125297328683087, 0.24377561533667613, 0.2037598808319182, 0.16914948745937275, 0.1952970847236929, 0.12159562377018596, 0.21591784336058972, 0.07526033107640473, 0.1492208804781554, 0.16253726989194217]\n"
     ]
    }
   ],
   "source": [
    "ElasticNet_rmse_ave(skew_x,y,[0.008],0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha\n",
      "[0.008, 0.008, 0.008, 0.008, 0.008, 0.008, 0.008, 0.008, 0.008, 0.008]\n",
      "\n",
      "\n",
      "l1_ratio\n",
      "[0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01]\n"
     ]
    }
   ],
   "source": [
    "alphas = [0.008]\n",
    "\n",
    "# alphas =[0.07,0.06,0.05,0.04, 0.03,0.02,0.01,0.005,0]\n",
    "l1ratio = [0.02,0.01,0.03,0.04,0.06,0.07]\n",
    "ElasticNet_alpha(skew_data[title],y,alphas,l1ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_rmse_ave: 0.0014730232992410653\n",
      "[0.0013233062301078369, 0.0015422951182855532, 0.0014638057497393874, 0.0011984609946683875, 0.0012734736978977578, 0.0015541200431389741, 0.0015358445604665583, 0.001707212143965393, 0.0014309604196231912, 0.001700754034517615]\n",
      "\n",
      "\n",
      "test_r2_ave: 0.21799046662102955\n",
      "[0.2492271453891981, 0.32251198929036873, 0.31998940171286017, 0.14422265282909152, 0.24203521840297526, 0.14388623903480846, 0.28192030826403425, 0.10495053947955135, 0.1718823175645363, 0.1992788542428715]\n"
     ]
    }
   ],
   "source": [
    "ElasticNet_rmse_ave(skew_data[title],y,[0.008],0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best params\n",
      "{'C': 1.3, 'epsilon': 0, 'gamma': 1e-07, 'kernel': 'linear'}\n",
      "\n",
      "\n",
      "best params\n",
      "{'C': 1.1, 'epsilon': 0, 'gamma': 1e-07, 'kernel': 'linear'}\n",
      "\n",
      "\n",
      "best params\n",
      "{'C': 1, 'epsilon': 0, 'gamma': 1e-07, 'kernel': 'linear'}\n",
      "\n",
      "\n",
      "best params\n",
      "{'C': 1.4, 'epsilon': 0, 'gamma': 1e-07, 'kernel': 'linear'}\n",
      "\n",
      "\n",
      "best params\n",
      "{'C': 1.3, 'epsilon': 0, 'gamma': 1e-07, 'kernel': 'linear'}\n",
      "\n",
      "\n",
      "best params\n",
      "{'C': 1.1, 'epsilon': 0, 'gamma': 1e-07, 'kernel': 'linear'}\n",
      "\n",
      "\n",
      "best params\n",
      "{'C': 1.2, 'epsilon': 0, 'gamma': 1e-07, 'kernel': 'linear'}\n",
      "\n",
      "\n",
      "best params\n",
      "{'C': 1.1, 'epsilon': 0, 'gamma': 1e-07, 'kernel': 'linear'}\n",
      "\n",
      "\n",
      "best params\n",
      "{'C': 1.2, 'epsilon': 0, 'gamma': 1e-07, 'kernel': 'linear'}\n",
      "\n",
      "\n",
      "best params\n",
      "{'C': 1, 'epsilon': 0, 'gamma': 1e-07, 'kernel': 'linear'}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# parameters = {'kernel': ('linear', 'rbf','poly'), 'C':[1.2,1.3,1,1.5],'gamma': [1e-7,1e-6 1e-8,5e-7],'epsilon':[0.2,0.5,0.3,0.4]}\n",
    "for i in np.arange(10):\n",
    "    X_SVR_train, X_SVR_test, y_SVR_train, y_SVR_test = train_test_split(skew_data[title], y, test_size=0.2, random_state=i)\n",
    "    parameters = {'kernel': ['linear'], 'C':[1.2,1.3,1.1,1.4,1],'gamma': [1e-7,5e-6,5e-7],'epsilon':[0.2,0.1,0.05,0]}\n",
    "    clf = GridSearchCV(estimator = SVR(), param_grid = parameters , n_jobs=6,iid=False, verbose=0,scoring='neg_mean_squared_error')\n",
    "    clf.fit(X_SVR_train,y_SVR_train)\n",
    "    print('best params')\n",
    "    print (clf.best_params_)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best params\n",
      "{'C': 1.6, 'epsilon': 0, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "\n",
      "\n",
      "best params\n",
      "{'C': 1.6, 'epsilon': 0, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "\n",
      "\n",
      "best params\n",
      "{'C': 1.6, 'epsilon': 0, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "\n",
      "\n",
      "best params\n",
      "{'C': 1.6, 'epsilon': 0, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "\n",
      "\n",
      "best params\n",
      "{'C': 1.6, 'epsilon': 0, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "\n",
      "\n",
      "best params\n",
      "{'C': 1.6, 'epsilon': 0, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "\n",
      "\n",
      "best params\n",
      "{'C': 1.6, 'epsilon': 0, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "\n",
      "\n",
      "best params\n",
      "{'C': 1.6, 'epsilon': 0, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "\n",
      "\n",
      "best params\n",
      "{'C': 1.6, 'epsilon': 0, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "\n",
      "\n",
      "best params\n",
      "{'C': 1.6, 'epsilon': 0, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# parameters = {'kernel': ('linear', 'rbf','poly'), 'C':[1.2,1.3,1,1.5],'gamma': [1e-7,1e-6 1e-8,5e-7],'epsilon':[0.2,0.5,0.3,0.4]}\n",
    "for i in np.arange(10):\n",
    "    X_SVR_train, X_SVR_test, y_SVR_train, y_SVR_test = train_test_split(skew_x, y, test_size=0.2, random_state=i)\n",
    "    parameters = {'kernel': [ 'rbf'], 'C':[1.6,1.5,1.8,1.9,2],'gamma': [1e-3,1e-5,1e-4,1e-2],'epsilon':[0.1,0.05,0,0.2]}\n",
    "    clf = GridSearchCV(estimator = SVR(), param_grid = parameters , n_jobs=6,iid=False, verbose=0,scoring='neg_mean_squared_error')\n",
    "    clf.fit(X_SVR_train,y_SVR_train)\n",
    "    print('best params')\n",
    "    print (clf.best_params_)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#best params {'C': 1.3, 'epsilon': 0.4, 'gamma': 1e-07, 'kernel': 'linear'}\n",
    "def svr_rmse_ave(data,fea_num,model):\n",
    "    y = data['Predict']\n",
    "    if fea_num != None:\n",
    "        num=data.select_dtypes(exclude='object')\n",
    "        numcorr=num.corr()\n",
    "        title=abs(numcorr['Predict']).sort_values(ascending=False).head(fea_num+1).to_frame().index.to_numpy()[1:]\n",
    "        X= data[title]\n",
    "    else:\n",
    "        X= data.drop(['Predict'], axis=1)\n",
    "    \n",
    "    train_rmse=[]\n",
    "    test_rmse=[]\n",
    "    test_r2=[]\n",
    "    \n",
    "    for i in np.arange(10):\n",
    "        x_train,x_test,y_train,y_test = train_test_split(X,y, random_state = i)\n",
    "        svr = model.fit(x_train,y_train)\n",
    "        y_train_pred = svr.predict(x_train)\n",
    "        y_test_pred = svr.predict(x_test)\n",
    "        train_rmse.append(mean_squared_error(y_train, y_train_pred,squared=False))\n",
    "        test_rmse.append(mean_squared_error(y_test, y_test_pred,squared=False))\n",
    "        test_r2.append(r2_score(y_test,y_test_pred))\n",
    "    \n",
    "    train_rmse=np.array(train_rmse).mean()\n",
    "    test_rmse=np.array(test_rmse).mean()\n",
    "    test_r2=np.array(test_r2).mean()\n",
    "    \n",
    "    print('train_rmse:', train_rmse)\n",
    "    print('test_rmse:', test_rmse)\n",
    "    print('test_r2:', test_r2)\n",
    "#     return train_rmse, test_rmse, test_r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_rmse: 0.001387491821286287\n",
      "test_rmse: 0.001426646714372851\n",
      "test_r2: 0.2438017820827147\n"
     ]
    }
   ],
   "source": [
    "model=SVR(kernel='linear', C=1.2, gamma= 1e-07, epsilon= 0)\n",
    "svr_rmse_ave(skew_data,6,model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_rmse: 0.00021142959856480743\n",
      "test_rmse: 0.001538392173221249\n",
      "test_r2: 0.12626012015126736\n"
     ]
    }
   ],
   "source": [
    "model=SVR(kernel='rbf', C=1.6, gamma= 0.01, epsilon= 0)\n",
    "svr_rmse_ave(skew_data,None,model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xgb_ave(x,y,model):\n",
    "    \n",
    "    rmse=[]\n",
    "    r2=[]\n",
    "\n",
    "    for i in np.arange(10):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=i)\n",
    "        model.fit(X_train,y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        rmse.append(math.sqrt(mean_squared_error(y_test, y_pred )))\n",
    "        r2.append(r2_score(y_test, y_pred ))\n",
    "    \n",
    "    test_rmse=np.array(rmse).mean()\n",
    "    print('test_rmse_ave:',test_rmse)\n",
    "    print(rmse)\n",
    "    print('\\n')\n",
    "    test_r2=np.array(r2).mean()\n",
    "    print('test_r2_ave:',test_r2)\n",
    "    print(r2)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### åèª¿ booster / n_estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[04:02:34] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "best params\n",
      "{'booster': 'dart', 'n_estimators': 60}\n",
      "\n",
      "\n",
      "[04:02:38] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "best params\n",
      "{'booster': 'dart', 'n_estimators': 60}\n",
      "\n",
      "\n",
      "[04:02:43] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "best params\n",
      "{'booster': 'dart', 'n_estimators': 60}\n",
      "\n",
      "\n",
      "[04:02:48] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "best params\n",
      "{'booster': 'dart', 'n_estimators': 70}\n",
      "\n",
      "\n",
      "[04:02:53] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "best params\n",
      "{'booster': 'dart', 'n_estimators': 60}\n",
      "\n",
      "\n",
      "[04:02:58] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "best params\n",
      "{'booster': 'dart', 'n_estimators': 60}\n",
      "\n",
      "\n",
      "[04:03:03] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "best params\n",
      "{'booster': 'dart', 'n_estimators': 60}\n",
      "\n",
      "\n",
      "[04:03:08] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "best params\n",
      "{'booster': 'dart', 'n_estimators': 60}\n",
      "\n",
      "\n",
      "[04:03:14] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "best params\n",
      "{'booster': 'dart', 'n_estimators': 70}\n",
      "\n",
      "\n",
      "[04:03:19] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "best params\n",
      "{'booster': 'dart', 'n_estimators': 60}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#for tuning parameters\n",
    "parameters_for_testing = {\n",
    "#     'booster':['gbtree','gblinear','dart'],\n",
    "    'booster':['dart'],\n",
    "    'n_estimators':range(10,201,10),\n",
    "}\n",
    "\n",
    "other_params = {'learning_rate': 0.1, 'n_estimators': 90, 'max_depth': 5, 'min_child_weight': 1, 'seed': 42,\n",
    "'subsample': 0.8, 'colsample_bytree': 0.8, 'gamma': 0, 'reg_alpha': 0, 'reg_lambda': 1}\n",
    "\n",
    "for i in np.arange(10):\n",
    "    X_XGB_train, X_XGB_test, y_XGB_train, y_XGB_test = train_test_split(skew_data[title], y, test_size=0.2, random_state=i)\n",
    "    xgb_model = XGBRegressor(**other_params)\n",
    "    gsearch = GridSearchCV(estimator = xgb_model, param_grid = parameters_for_testing, n_jobs=6,iid=False, verbose=0,scoring='neg_mean_squared_error')\n",
    "    gsearch.fit(X_XGB_train,y_XGB_train)\n",
    "    print('best params')\n",
    "    print (gsearch.best_params_)\n",
    "    print('\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:37:03] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "best params\n",
      "{'booster': 'gbtree', 'n_estimators': 200}\n",
      "\n",
      "\n",
      "[15:37:11] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "best params\n",
      "{'booster': 'gbtree', 'n_estimators': 100}\n",
      "\n",
      "\n",
      "[15:37:21] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "best params\n",
      "{'booster': 'gbtree', 'n_estimators': 140}\n",
      "\n",
      "\n",
      "[15:37:32] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "best params\n",
      "{'booster': 'gbtree', 'n_estimators': 150}\n",
      "\n",
      "\n",
      "[15:37:42] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "best params\n",
      "{'booster': 'gbtree', 'n_estimators': 110}\n",
      "\n",
      "\n",
      "[15:37:51] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "best params\n",
      "{'booster': 'gbtree', 'n_estimators': 110}\n",
      "\n",
      "\n",
      "[15:38:00] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "best params\n",
      "{'booster': 'gbtree', 'n_estimators': 150}\n",
      "\n",
      "\n",
      "[15:38:09] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "best params\n",
      "{'booster': 'gbtree', 'n_estimators': 130}\n",
      "\n",
      "\n",
      "[15:38:20] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "best params\n",
      "{'booster': 'gbtree', 'n_estimators': 130}\n",
      "\n",
      "\n",
      "[15:38:34] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "best params\n",
      "{'booster': 'gbtree', 'n_estimators': 180}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#for tuning parameters\n",
    "parameters_for_testing = {\n",
    "#     'booster':['gbtree','gblinear','dart'],\n",
    "    'booster':['gbtree'],\n",
    "#     'n_estimators':[90,100],\n",
    "    'n_estimators':range(90,221,10),\n",
    "}\n",
    "\n",
    "other_params = {'learning_rate': 0.1, 'max_depth': 5, 'min_child_weight': 1, 'seed': 42,\n",
    "'subsample': 0.8, 'colsample_bytree': 0.8, 'gamma': 0, 'reg_alpha': 0, 'reg_lambda': 1}\n",
    "\n",
    "for i in np.arange(10):\n",
    "    X_XGB_train, X_XGB_test, y_XGB_train, y_XGB_test = train_test_split(skew_x, y, test_size=0.2, random_state=i)\n",
    "    xgb_model = XGBRegressor(**other_params)\n",
    "    gsearch = GridSearchCV(estimator = xgb_model, param_grid = parameters_for_testing, n_jobs=6,iid=False, verbose=0,scoring='neg_mean_squared_error')\n",
    "    gsearch.fit(X_XGB_train,y_XGB_train)\n",
    "    print('best params')\n",
    "    print (gsearch.best_params_)\n",
    "    print('\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### èª¿ max_depth / min_child_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[04:04:56] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "best params\n",
      "{'max_depth': 2, 'min_child_weight': 2}\n",
      "\n",
      "\n",
      "[04:04:57] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "best params\n",
      "{'max_depth': 2, 'min_child_weight': 1}\n",
      "\n",
      "\n",
      "[04:04:57] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "best params\n",
      "{'max_depth': 2, 'min_child_weight': 1}\n",
      "\n",
      "\n",
      "[04:04:57] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "best params\n",
      "{'max_depth': 2, 'min_child_weight': 4}\n",
      "\n",
      "\n",
      "[04:04:58] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "best params\n",
      "{'max_depth': 2, 'min_child_weight': 1}\n",
      "\n",
      "\n",
      "[04:04:58] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "best params\n",
      "{'max_depth': 2, 'min_child_weight': 5}\n",
      "\n",
      "\n",
      "[04:04:58] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "best params\n",
      "{'max_depth': 2, 'min_child_weight': 2}\n",
      "\n",
      "\n",
      "[04:04:59] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "best params\n",
      "{'max_depth': 2, 'min_child_weight': 1}\n",
      "\n",
      "\n",
      "[04:04:59] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "best params\n",
      "{'max_depth': 2, 'min_child_weight': 2}\n",
      "\n",
      "\n",
      "[04:05:00] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "best params\n",
      "{'max_depth': 2, 'min_child_weight': 1}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# {'booster': 'dart', 'n_estimators': 60}\n",
    "\n",
    "parameters_for_testing = {\n",
    "#     'max_depth': [1,2,3, 4, 5, 6, 7, 8, 9, 10],\n",
    "    'max_depth': [2],\n",
    "    'min_child_weight': [1, 2, 3, 4, 5, 6]\n",
    "}\n",
    "\n",
    "other_params = {'booster':'dart','learning_rate': 0.1, 'n_estimators': 60, 'seed': 42,\n",
    "'subsample': 0.8, 'colsample_bytree': 0.8, 'gamma': 0, 'reg_alpha': 0, 'reg_lambda': 1}\n",
    "\n",
    "for i in np.arange(10):\n",
    "    X_XGB_train, X_XGB_test, y_XGB_train, y_XGB_test = train_test_split(skew_data[title], y, test_size=0.2, random_state=i)\n",
    "    xgb_model = XGBRegressor(**other_params)\n",
    "    gsearch = GridSearchCV(estimator = xgb_model, param_grid = parameters_for_testing, n_jobs=6,iid=False, verbose=0,scoring='neg_mean_squared_error')\n",
    "    gsearch.fit(X_XGB_train,y_XGB_train)\n",
    "    print('best params')\n",
    "    print (gsearch.best_params_)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:46:28] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "best params\n",
      "{'max_depth': 5, 'min_child_weight': 6}\n",
      "\n",
      "\n",
      "[15:46:32] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "best params\n",
      "{'max_depth': 5, 'min_child_weight': 2}\n",
      "\n",
      "\n",
      "[15:46:35] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "best params\n",
      "{'max_depth': 5, 'min_child_weight': 2}\n",
      "\n",
      "\n",
      "[15:46:39] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "best params\n",
      "{'max_depth': 5, 'min_child_weight': 6}\n",
      "\n",
      "\n",
      "[15:46:43] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "best params\n",
      "{'max_depth': 5, 'min_child_weight': 4}\n",
      "\n",
      "\n",
      "[15:46:46] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "best params\n",
      "{'max_depth': 5, 'min_child_weight': 3}\n",
      "\n",
      "\n",
      "[15:46:50] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "best params\n",
      "{'max_depth': 5, 'min_child_weight': 3}\n",
      "\n",
      "\n",
      "[15:46:54] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "best params\n",
      "{'max_depth': 5, 'min_child_weight': 4}\n",
      "\n",
      "\n",
      "[15:46:57] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "best params\n",
      "{'max_depth': 5, 'min_child_weight': 6}\n",
      "\n",
      "\n",
      "[15:47:01] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "best params\n",
      "{'max_depth': 5, 'min_child_weight': 4}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# {'booster': 'dart', 'n_estimators': 160}\n",
    "\n",
    "parameters_for_testing = {\n",
    "#     'max_depth': [1,2,3, 4, 5, 6, 7, 8, 9, 10],\n",
    "    'max_depth': [5],\n",
    "    'min_child_weight': [1, 2, 3, 4, 5, 6]\n",
    "}\n",
    "\n",
    "other_params = {'booster':'gbtree','learning_rate': 0.1, 'n_estimators': 140, 'seed': 42,\n",
    "'subsample': 0.8, 'colsample_bytree': 0.8, 'gamma': 0, 'reg_alpha': 0, 'reg_lambda': 1}\n",
    "\n",
    "for i in np.arange(10):\n",
    "    X_XGB_train, X_XGB_test, y_XGB_train, y_XGB_test = train_test_split(skew_x, y, test_size=0.2, random_state=i)\n",
    "    xgb_model = XGBRegressor(**other_params)\n",
    "    gsearch = GridSearchCV(estimator = xgb_model, param_grid = parameters_for_testing, n_jobs=6,iid=False, verbose=0,scoring='neg_mean_squared_error')\n",
    "    gsearch.fit(X_XGB_train,y_XGB_train)\n",
    "    print('best params')\n",
    "    print (gsearch.best_params_)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### èª¿ gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[04:05:43] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "best params\n",
      "{'gamma': 0}\n",
      "\n",
      "\n",
      "[04:05:44] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "best params\n",
      "{'gamma': 0}\n",
      "\n",
      "\n",
      "[04:05:44] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "best params\n",
      "{'gamma': 0}\n",
      "\n",
      "\n",
      "[04:05:45] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "best params\n",
      "{'gamma': 0}\n",
      "\n",
      "\n",
      "[04:05:45] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "best params\n",
      "{'gamma': 0}\n",
      "\n",
      "\n",
      "[04:05:46] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "best params\n",
      "{'gamma': 0}\n",
      "\n",
      "\n",
      "[04:05:46] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "best params\n",
      "{'gamma': 0}\n",
      "\n",
      "\n",
      "[04:05:47] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "best params\n",
      "{'gamma': 0}\n",
      "\n",
      "\n",
      "[04:05:47] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "best params\n",
      "{'gamma': 0}\n",
      "\n",
      "\n",
      "[04:05:48] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "best params\n",
      "{'gamma': 0}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# {'max_depth': 2, 'min_child_weight': 2}\n",
    "parameters_for_testing = {\n",
    "    'gamma': [0,0.1, 0.2, 0.3, 0.4, 0.5, 0.6]\n",
    "}\n",
    "\n",
    "other_params = {'booster':'dart','learning_rate': 0.1, 'n_estimators': 60, 'max_depth': 2, 'min_child_weight': 2, 'seed': 42,\n",
    "'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0, 'reg_lambda': 1}\n",
    "\n",
    "for i in np.arange(10):\n",
    "    X_XGB_train, X_XGB_test, y_XGB_train, y_XGB_test = train_test_split(skew_data[title], y, test_size=0.2, random_state=i)\n",
    "    xgb_model = XGBRegressor(**other_params)\n",
    "    gsearch = GridSearchCV(estimator = xgb_model, param_grid = parameters_for_testing, n_jobs=6,iid=False, verbose=0,scoring='neg_mean_squared_error')\n",
    "    gsearch.fit(X_XGB_train,y_XGB_train)\n",
    "    print('best params')\n",
    "    print (gsearch.best_params_)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:47:52] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "best params\n",
      "{'gamma': 0}\n",
      "\n",
      "\n",
      "[15:47:58] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "best params\n",
      "{'gamma': 0}\n",
      "\n",
      "\n",
      "[15:48:05] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "best params\n",
      "{'gamma': 0}\n",
      "\n",
      "\n",
      "[15:48:12] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "best params\n",
      "{'gamma': 0}\n",
      "\n",
      "\n",
      "[15:48:20] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "best params\n",
      "{'gamma': 0}\n",
      "\n",
      "\n",
      "[15:48:26] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "best params\n",
      "{'gamma': 0}\n",
      "\n",
      "\n",
      "[15:48:35] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "best params\n",
      "{'gamma': 0}\n",
      "\n",
      "\n",
      "[15:48:43] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "best params\n",
      "{'gamma': 0}\n",
      "\n",
      "\n",
      "[15:48:48] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "best params\n",
      "{'gamma': 0}\n",
      "\n",
      "\n",
      "[15:48:55] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "best params\n",
      "{'gamma': 0}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# {'max_depth': 5, 'min_child_weight': 4}\n",
    "parameters_for_testing = {\n",
    "    'gamma': [0,0.1, 0.2, 0.3, 0.4, 0.5, 0.6]\n",
    "}\n",
    "\n",
    "other_params = {'booster':'gbtree','learning_rate': 0.1, 'n_estimators': 140, 'max_depth': 5, 'min_child_weight': 4, 'seed': 42,\n",
    "'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0, 'reg_lambda': 1}\n",
    "\n",
    "for i in np.arange(10):\n",
    "    X_XGB_train, X_XGB_test, y_XGB_train, y_XGB_test = train_test_split(skew_x, y, test_size=0.2, random_state=i)\n",
    "    xgb_model = XGBRegressor(**other_params)\n",
    "    gsearch = GridSearchCV(estimator = xgb_model, param_grid = parameters_for_testing, n_jobs=6,iid=False, verbose=0,scoring='neg_mean_squared_error')\n",
    "    gsearch.fit(X_XGB_train,y_XGB_train)\n",
    "    print('best params')\n",
    "    print (gsearch.best_params_)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### èª¿ subsample / colsample_bytree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[04:09:16] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "best params\n",
      "{'colsample_bytree': 0.5, 'subsample': 0.3}\n",
      "\n",
      "\n",
      "[04:09:16] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "best params\n",
      "{'colsample_bytree': 0.5, 'subsample': 0.7}\n",
      "\n",
      "\n",
      "[04:09:17] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "best params\n",
      "{'colsample_bytree': 0.5, 'subsample': 0.7}\n",
      "\n",
      "\n",
      "[04:09:17] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "best params\n",
      "{'colsample_bytree': 0.5, 'subsample': 0.7}\n",
      "\n",
      "\n",
      "[04:09:18] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "best params\n",
      "{'colsample_bytree': 0.5, 'subsample': 0.9}\n",
      "\n",
      "\n",
      "[04:09:18] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "best params\n",
      "{'colsample_bytree': 0.5, 'subsample': 0.9}\n",
      "\n",
      "\n",
      "[04:09:19] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "best params\n",
      "{'colsample_bytree': 0.5, 'subsample': 0.7}\n",
      "\n",
      "\n",
      "[04:09:20] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "best params\n",
      "{'colsample_bytree': 0.5, 'subsample': 0.5}\n",
      "\n",
      "\n",
      "[04:09:20] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "best params\n",
      "{'colsample_bytree': 0.5, 'subsample': 0.6}\n",
      "\n",
      "\n",
      "[04:09:21] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "best params\n",
      "{'colsample_bytree': 0.5, 'subsample': 0.5}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# {'gamma': 0}\n",
    "parameters_for_testing = {\n",
    "#     'colsample_bytree': [0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],\n",
    "    'colsample_bytree': [0.5],\n",
    "    'subsample': [0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9] \n",
    "}\n",
    "\n",
    "other_params = {'booster':'dart','learning_rate': 0.1, 'n_estimators': 60, 'max_depth': 2, 'min_child_weight': 2, 'seed': 42,\n",
    " 'reg_alpha': 0, 'reg_lambda': 1, 'gamma':0}\n",
    "\n",
    "for i in np.arange(10):\n",
    "    X_XGB_train, X_XGB_test, y_XGB_train, y_XGB_test = train_test_split(skew_data[title], y, test_size=0.2, random_state=i)\n",
    "    xgb_model = XGBRegressor(**other_params)\n",
    "    gsearch = GridSearchCV(estimator = xgb_model, param_grid = parameters_for_testing, n_jobs=6,iid=False, verbose=0,scoring='neg_mean_squared_error')\n",
    "    gsearch.fit(X_XGB_train,y_XGB_train)\n",
    "    print('best params')\n",
    "    print (gsearch.best_params_)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:55:35] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "best params\n",
      "{'colsample_bytree': 0.5, 'subsample': 0.7}\n",
      "\n",
      "\n",
      "[15:55:40] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "best params\n",
      "{'colsample_bytree': 0.5, 'subsample': 0.9}\n",
      "\n",
      "\n",
      "[15:55:44] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "best params\n",
      "{'colsample_bytree': 0.5, 'subsample': 0.8}\n",
      "\n",
      "\n",
      "[15:55:48] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "best params\n",
      "{'colsample_bytree': 0.5, 'subsample': 0.9}\n",
      "\n",
      "\n",
      "[15:55:52] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "best params\n",
      "{'colsample_bytree': 0.5, 'subsample': 0.9}\n",
      "\n",
      "\n",
      "[15:55:58] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "best params\n",
      "{'colsample_bytree': 0.5, 'subsample': 0.7}\n",
      "\n",
      "\n",
      "[15:56:04] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "best params\n",
      "{'colsample_bytree': 0.5, 'subsample': 0.8}\n",
      "\n",
      "\n",
      "[15:56:09] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "best params\n",
      "{'colsample_bytree': 0.5, 'subsample': 0.5}\n",
      "\n",
      "\n",
      "[15:56:13] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "best params\n",
      "{'colsample_bytree': 0.5, 'subsample': 0.9}\n",
      "\n",
      "\n",
      "[15:56:19] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "best params\n",
      "{'colsample_bytree': 0.5, 'subsample': 0.6}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# {'gamma': 0}\n",
    "parameters_for_testing = {\n",
    "#     'colsample_bytree': [0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],\n",
    "    'colsample_bytree': [0.5],\n",
    "    'subsample': [0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9] \n",
    "}\n",
    "\n",
    "other_params = {'booster':'gbtree','learning_rate': 0.1, 'n_estimators': 140, 'max_depth': 5, 'min_child_weight': 4, 'seed': 42,\n",
    " 'reg_alpha': 0, 'reg_lambda': 1, 'gamma':0}\n",
    "\n",
    "for i in np.arange(10):\n",
    "    X_XGB_train, X_XGB_test, y_XGB_train, y_XGB_test = train_test_split(skew_x, y, test_size=0.2, random_state=i)\n",
    "    xgb_model = XGBRegressor(**other_params)\n",
    "    gsearch = GridSearchCV(estimator = xgb_model, param_grid = parameters_for_testing, n_jobs=6,iid=False, verbose=0,scoring='neg_mean_squared_error')\n",
    "    gsearch.fit(X_XGB_train,y_XGB_train)\n",
    "    print('best params')\n",
    "    print (gsearch.best_params_)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### reg_alpha / reg_lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[04:10:13] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "best params\n",
      "{'reg_alpha': 0, 'reg_lambda': 1}\n",
      "\n",
      "\n",
      "[04:10:15] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "best params\n",
      "{'reg_alpha': 0, 'reg_lambda': 0.5}\n",
      "\n",
      "\n",
      "[04:10:18] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "best params\n",
      "{'reg_alpha': 0, 'reg_lambda': 0.5}\n",
      "\n",
      "\n",
      "[04:10:20] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "best params\n",
      "{'reg_alpha': 0, 'reg_lambda': 0.5}\n",
      "\n",
      "\n",
      "[04:10:22] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "best params\n",
      "{'reg_alpha': 0, 'reg_lambda': 1}\n",
      "\n",
      "\n",
      "[04:10:25] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "best params\n",
      "{'reg_alpha': 0, 'reg_lambda': 1}\n",
      "\n",
      "\n",
      "[04:10:27] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "best params\n",
      "{'reg_alpha': 0, 'reg_lambda': 0.1}\n",
      "\n",
      "\n",
      "[04:10:29] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "best params\n",
      "{'reg_alpha': 0, 'reg_lambda': 0.05}\n",
      "\n",
      "\n",
      "[04:10:32] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "best params\n",
      "{'reg_alpha': 0, 'reg_lambda': 1}\n",
      "\n",
      "\n",
      "[04:10:35] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "best params\n",
      "{'reg_alpha': 0, 'reg_lambda': 1}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# {'colsample_bytree': 0.5, 'subsample': 0.6}\n",
    "\n",
    "parameters_for_testing = {\n",
    "    'reg_alpha': [0,0.05, 0.1, 0.5 , 1, 2, 3], \n",
    "#     'reg_alpha': [0.5],     \n",
    "    'reg_lambda': [0.05, 0.1, 0.5 , 1, 2, 3]\n",
    "}\n",
    "\n",
    "other_params = {'booster':'dart','learning_rate': 0.1, 'n_estimators': 60, 'max_depth': 2, 'min_child_weight': 2, 'seed': 42,\n",
    " 'gamma':0,'subsample':0.6,'colsample_bytree': 0.5}\n",
    "\n",
    "\n",
    "for i in np.arange(10):\n",
    "    X_XGB_train, X_XGB_test, y_XGB_train, y_XGB_test = train_test_split(skew_data[title], y, test_size=0.2, random_state=i)\n",
    "    xgb_model = XGBRegressor(**other_params)\n",
    "    gsearch = GridSearchCV(estimator = xgb_model, param_grid = parameters_for_testing, n_jobs=6,iid=False, verbose=0,scoring='neg_mean_squared_error')\n",
    "    gsearch.fit(X_XGB_train,y_XGB_train)\n",
    "    print('best params')\n",
    "    print (gsearch.best_params_)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:57:26] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "best params\n",
      "{'reg_alpha': 0, 'reg_lambda': 0.5}\n",
      "\n",
      "\n",
      "[15:57:43] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "best params\n",
      "{'reg_alpha': 0, 'reg_lambda': 0.05}\n",
      "\n",
      "\n",
      "[15:58:00] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "best params\n",
      "{'reg_alpha': 0, 'reg_lambda': 1}\n",
      "\n",
      "\n",
      "[15:58:17] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "best params\n",
      "{'reg_alpha': 0, 'reg_lambda': 0.05}\n",
      "\n",
      "\n",
      "[15:58:33] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "best params\n",
      "{'reg_alpha': 0, 'reg_lambda': 0.5}\n",
      "\n",
      "\n",
      "[15:58:59] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "best params\n",
      "{'reg_alpha': 0, 'reg_lambda': 0.05}\n",
      "\n",
      "\n",
      "[15:59:14] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "best params\n",
      "{'reg_alpha': 0, 'reg_lambda': 0.1}\n",
      "\n",
      "\n",
      "[15:59:30] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "best params\n",
      "{'reg_alpha': 0, 'reg_lambda': 0.5}\n",
      "\n",
      "\n",
      "[15:59:48] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "best params\n",
      "{'reg_alpha': 0, 'reg_lambda': 0.05}\n",
      "\n",
      "\n",
      "[16:00:17] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "best params\n",
      "{'reg_alpha': 0, 'reg_lambda': 0.1}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# {'colsample_bytree': 0.9, 'subsample': 0.7}\n",
    "\n",
    "parameters_for_testing = {\n",
    "    'reg_alpha': [0,0.05, 0.1, 0.5 , 1, 2, 3], \n",
    "#     'reg_alpha': [0.02],     \n",
    "    'reg_lambda': [0.05, 0.1, 0.5 , 1, 2, 3]\n",
    "}\n",
    "\n",
    "other_params = {'booster':'gbtree','learning_rate': 0.1, 'n_estimators': 140, 'max_depth': 5, 'min_child_weight': 4, 'seed': 42,\n",
    " 'gamma':0,'subsample':0.7,'colsample_bytree': 0.5}\n",
    "\n",
    "\n",
    "for i in np.arange(10):\n",
    "    X_XGB_train, X_XGB_test, y_XGB_train, y_XGB_test = train_test_split(skew_x, y, test_size=0.2, random_state=i)\n",
    "    xgb_model = XGBRegressor(**other_params)\n",
    "    gsearch = GridSearchCV(estimator = xgb_model, param_grid = parameters_for_testing, n_jobs=6,iid=False, verbose=0,scoring='neg_mean_squared_error')\n",
    "    gsearch.fit(X_XGB_train,y_XGB_train)\n",
    "    print('best params')\n",
    "    print (gsearch.best_params_)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[04:11:43] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "best params\n",
      "{'learning_rate': 0.1}\n",
      "\n",
      "\n",
      "[04:11:43] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "best params\n",
      "{'learning_rate': 0.1}\n",
      "\n",
      "\n",
      "[04:11:44] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "best params\n",
      "{'learning_rate': 0.1}\n",
      "\n",
      "\n",
      "[04:11:44] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "best params\n",
      "{'learning_rate': 0.1}\n",
      "\n",
      "\n",
      "[04:11:44] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "best params\n",
      "{'learning_rate': 0.1}\n",
      "\n",
      "\n",
      "[04:11:45] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "best params\n",
      "{'learning_rate': 0.2}\n",
      "\n",
      "\n",
      "[04:11:45] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "best params\n",
      "{'learning_rate': 0.2}\n",
      "\n",
      "\n",
      "[04:11:46] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "best params\n",
      "{'learning_rate': 0.1}\n",
      "\n",
      "\n",
      "[04:11:46] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "best params\n",
      "{'learning_rate': 0.1}\n",
      "\n",
      "\n",
      "[04:11:46] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "best params\n",
      "{'learning_rate': 0.1}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# {'reg_alpha': 0, 'reg_lambda': 0.7}\n",
    "\n",
    "parameters_for_testing = {\n",
    "   'learning_rate': [0.01, 0.05, 0.07, 0.1, 0.2]\n",
    "}\n",
    "\n",
    "other_params = {'booster':'dart', 'n_estimators': 60, 'max_depth': 2, 'min_child_weight': 2, 'seed': 42,\n",
    " 'gamma':0,'subsample':0.6,'colsample_bytree': 0.5,'reg_alpha': 0, 'reg_lambda': 0.7}\n",
    "\n",
    "for i in np.arange(10):\n",
    "    X_XGB_train, X_XGB_test, y_XGB_train, y_XGB_test = train_test_split(skew_data[title], y, test_size=0.2, random_state=i)\n",
    "    xgb_model = XGBRegressor(**other_params)\n",
    "    gsearch = GridSearchCV(estimator = xgb_model, param_grid = parameters_for_testing, n_jobs=6,iid=False, verbose=0,scoring='neg_mean_squared_error')\n",
    "    gsearch.fit(X_XGB_train,y_XGB_train)\n",
    "    print('best params')\n",
    "    print (gsearch.best_params_)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:01:14] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "best params\n",
      "{'learning_rate': 0.07}\n",
      "\n",
      "\n",
      "[16:01:17] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "best params\n",
      "{'learning_rate': 0.07}\n",
      "\n",
      "\n",
      "[16:01:19] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "best params\n",
      "{'learning_rate': 0.07}\n",
      "\n",
      "\n",
      "[16:01:22] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "best params\n",
      "{'learning_rate': 0.07}\n",
      "\n",
      "\n",
      "[16:01:25] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "best params\n",
      "{'learning_rate': 0.1}\n",
      "\n",
      "\n",
      "[16:01:28] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "best params\n",
      "{'learning_rate': 0.07}\n",
      "\n",
      "\n",
      "[16:01:31] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "best params\n",
      "{'learning_rate': 0.07}\n",
      "\n",
      "\n",
      "[16:01:34] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "best params\n",
      "{'learning_rate': 0.07}\n",
      "\n",
      "\n",
      "[16:01:37] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "best params\n",
      "{'learning_rate': 0.1}\n",
      "\n",
      "\n",
      "[16:01:40] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "best params\n",
      "{'learning_rate': 0.07}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# {'reg_alpha': 0.0, 'reg_lambda': 0.3}\n",
    "\n",
    "parameters_for_testing = {\n",
    "   'learning_rate': [0.01, 0.05, 0.07, 0.1, 0.2]\n",
    "}\n",
    "\n",
    "other_params = {'booster':'gbtree','learning_rate': 0.1, 'n_estimators': 140, 'max_depth': 5, 'min_child_weight': 4, 'seed': 42,\n",
    " 'gamma':0,'subsample':0.7,'colsample_bytree': 0.5,'reg_alpha': 0, 'reg_lambda': 0.3}\n",
    "\n",
    "for i in np.arange(10):\n",
    "    X_XGB_train, X_XGB_test, y_XGB_train, y_XGB_test = train_test_split(skew_x, y, test_size=0.2, random_state=i)\n",
    "    xgb_model = XGBRegressor(**other_params)\n",
    "    gsearch = GridSearchCV(estimator = xgb_model, param_grid = parameters_for_testing, n_jobs=6,iid=False, verbose=0,scoring='neg_mean_squared_error')\n",
    "    gsearch.fit(X_XGB_train,y_XGB_train)\n",
    "    print('best params')\n",
    "    print (gsearch.best_params_)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_rmse_ave: 0.008496031540705907\n",
      "[0.007648650629856374, 0.007861428699795805, 0.008923526006532567, 0.008422016710058338, 0.007514787893473913, 0.007671313900216453, 0.009908224384169528, 0.0094945394022681, 0.008777706642056635, 0.008738121138631347]\n",
      "\n",
      "\n",
      "test_r2_ave: 0.5658204873179591\n",
      "[0.6994093043442213, 0.6676009790074625, 0.49424336268772506, 0.5730727307503245, 0.6729951732468282, 0.6589820348516682, 0.3470225948052349, 0.46909149956225205, 0.5156770986673376, 0.5601100952565365]\n"
     ]
    }
   ],
   "source": [
    "best_xgb_model = XGBRegressor(\n",
    "                objective ='reg:squarederror',\n",
    "              learning_rate = 0.1,\n",
    "              booster = 'dart', \n",
    "              n_estimators = 60, \n",
    "              max_depth = 2, \n",
    "              min_child_weight = 2,\n",
    "              seed = 42,\n",
    "              gamma = 0,\n",
    "              subsample = 0.6,\n",
    "              colsample_bytree = 0.5,\n",
    "              reg_alpha =  0,\n",
    "              reg_lambda = 0.7)\n",
    "xgb_ave(skew_data[title], y,best_xgb_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_rmse_ave: 0.00146814958507051\n",
      "[0.001374547660024547, 0.001499748552306931, 0.0015095238573869703, 0.0011667653775258547, 0.001297103823892872, 0.0016228185258738358, 0.0014456482123968704, 0.0016769517389853613, 0.001450769262021827, 0.0016376188402900324]\n",
      "\n",
      "\n",
      "test_r2_ave: 0.2201848600729715\n",
      "[0.18995815719425213, 0.3593754924018251, 0.2768494072214931, 0.18888945934509394, 0.21364519107289193, 0.06652590836192707, 0.3637857918345734, 0.1363989119490141, 0.14879629308566833, 0.2576239882629757]\n"
     ]
    }
   ],
   "source": [
    "best_xgb_model = XGBRegressor(\n",
    "                objective ='reg:squarederror',\n",
    "              learning_rate = 0.08,\n",
    "              booster = 'gbtree', \n",
    "              n_estimators = 140, \n",
    "              max_depth = 5, \n",
    "              min_child_weight = 4,\n",
    "              seed = 42,\n",
    "              gamma = 0,\n",
    "              subsample = 0.7,\n",
    "              colsample_bytree = 0.5,\n",
    "              reg_alpha =  0,\n",
    "              reg_lambda = 0.3)\n",
    "xgb_ave(skew_x, y,best_xgb_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rand_ave(x,y,model):\n",
    "    \n",
    "    rmse=[]\n",
    "    r2=[]\n",
    "\n",
    "    for i in np.arange(10):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=i)\n",
    "        model.fit(X_train,y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        rmse.append(math.sqrt(mean_squared_error(y_test, y_pred )))\n",
    "        r2.append(r2_score(y_test, y_pred ))\n",
    "    \n",
    "    test_rmse=np.array(rmse).mean()\n",
    "    print('test_rmse_ave:',test_rmse)\n",
    "    print(rmse)\n",
    "    print('\\n')\n",
    "    test_r2=np.array(r2).mean()\n",
    "    print('test_r2_ave:',test_r2)\n",
    "    print(r2)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "clf = RandomForestRegressor(\n",
    "          criterion ='mse', \n",
    "          random_state = 42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_RAND_train, X_RAND_test, y_RAND_train, y_RAND_test = train_test_split(skew_data[title], y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 360 candidates, totalling 1800 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done   1 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=6)]: Batch computation too fast (0.0688s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=6)]: Done   6 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=6)]: Done  14 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=6)]: Done  28 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=6)]: Done  46 tasks      | elapsed:    1.8s\n",
      "[Parallel(n_jobs=6)]: Done  64 tasks      | elapsed:    2.3s\n",
      "[Parallel(n_jobs=6)]: Done  86 tasks      | elapsed:    3.1s\n",
      "[Parallel(n_jobs=6)]: Done 108 tasks      | elapsed:    3.8s\n",
      "[Parallel(n_jobs=6)]: Done 134 tasks      | elapsed:    4.8s\n",
      "[Parallel(n_jobs=6)]: Done 160 tasks      | elapsed:    5.9s\n",
      "[Parallel(n_jobs=6)]: Done 190 tasks      | elapsed:    7.3s\n",
      "[Parallel(n_jobs=6)]: Done 220 tasks      | elapsed:    8.4s\n",
      "[Parallel(n_jobs=6)]: Done 254 tasks      | elapsed:    9.5s\n",
      "[Parallel(n_jobs=6)]: Done 288 tasks      | elapsed:   10.9s\n",
      "[Parallel(n_jobs=6)]: Done 326 tasks      | elapsed:   12.3s\n",
      "[Parallel(n_jobs=6)]: Done 364 tasks      | elapsed:   14.0s\n",
      "[Parallel(n_jobs=6)]: Done 406 tasks      | elapsed:   15.5s\n",
      "[Parallel(n_jobs=6)]: Done 448 tasks      | elapsed:   17.5s\n",
      "[Parallel(n_jobs=6)]: Done 494 tasks      | elapsed:   19.6s\n",
      "[Parallel(n_jobs=6)]: Done 540 tasks      | elapsed:   21.6s\n",
      "[Parallel(n_jobs=6)]: Done 590 tasks      | elapsed:   24.7s\n",
      "[Parallel(n_jobs=6)]: Batch computation too slow (2.0688s.) Setting batch_size=1.\n",
      "[Parallel(n_jobs=6)]: Done 640 tasks      | elapsed:   28.7s\n",
      "[Parallel(n_jobs=6)]: Done 677 tasks      | elapsed:   30.7s\n",
      "[Parallel(n_jobs=6)]: Done 704 tasks      | elapsed:   31.7s\n",
      "[Parallel(n_jobs=6)]: Done 733 tasks      | elapsed:   32.7s\n",
      "[Parallel(n_jobs=6)]: Done 762 tasks      | elapsed:   34.1s\n",
      "[Parallel(n_jobs=6)]: Done 793 tasks      | elapsed:   35.3s\n",
      "[Parallel(n_jobs=6)]: Done 824 tasks      | elapsed:   36.6s\n",
      "[Parallel(n_jobs=6)]: Done 857 tasks      | elapsed:   37.9s\n",
      "[Parallel(n_jobs=6)]: Done 890 tasks      | elapsed:   39.5s\n",
      "[Parallel(n_jobs=6)]: Done 925 tasks      | elapsed:   41.2s\n",
      "[Parallel(n_jobs=6)]: Done 960 tasks      | elapsed:   43.0s\n",
      "[Parallel(n_jobs=6)]: Done 997 tasks      | elapsed:   45.3s\n",
      "[Parallel(n_jobs=6)]: Done 1034 tasks      | elapsed:   47.3s\n",
      "[Parallel(n_jobs=6)]: Done 1073 tasks      | elapsed:   49.9s\n",
      "[Parallel(n_jobs=6)]: Done 1112 tasks      | elapsed:   51.7s\n",
      "[Parallel(n_jobs=6)]: Done 1153 tasks      | elapsed:   53.7s\n",
      "[Parallel(n_jobs=6)]: Done 1194 tasks      | elapsed:   55.4s\n",
      "[Parallel(n_jobs=6)]: Done 1237 tasks      | elapsed:   58.1s\n",
      "[Parallel(n_jobs=6)]: Done 1280 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=6)]: Done 1325 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=6)]: Done 1370 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=6)]: Done 1417 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=6)]: Done 1464 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=6)]: Done 1513 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=6)]: Done 1562 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=6)]: Done 1613 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=6)]: Done 1664 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=6)]: Done 1717 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=6)]: Done 1770 tasks      | elapsed:  1.4min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best params\n",
      "{'max_depth': 4, 'min_samples_split': 4, 'n_estimators': 50}\n",
      "best score\n",
      "-6.733198261475197e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Done 1800 out of 1800 | elapsed:  1.4min finished\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "#               'n_estimators': [50,100,200 ,500, 900],\n",
    "              'n_estimators': [20,40,50,60,80],\n",
    "              'max_depth': range(1,10,1),\n",
    "              'min_samples_split': range(2,10,1)}\n",
    "\n",
    "gsearch = GridSearchCV(estimator = clf, param_grid = param_grid, n_jobs=6,iid=False, verbose=10,scoring='neg_mean_squared_error')\n",
    "\n",
    "gsearch.fit(X_RAND_train,y_RAND_train)\n",
    "\n",
    "print('best params')\n",
    "print (gsearch.best_params_)\n",
    "print('best score')\n",
    "print (gsearch.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 117 candidates, totalling 585 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done   1 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=6)]: Done   6 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=6)]: Done  13 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=6)]: Done  20 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=6)]: Done  29 tasks      | elapsed:    1.2s\n",
      "[Parallel(n_jobs=6)]: Done  38 tasks      | elapsed:    1.6s\n",
      "[Parallel(n_jobs=6)]: Done  49 tasks      | elapsed:    2.1s\n",
      "[Parallel(n_jobs=6)]: Done  60 tasks      | elapsed:    2.5s\n",
      "[Parallel(n_jobs=6)]: Done  73 tasks      | elapsed:    3.2s\n",
      "[Parallel(n_jobs=6)]: Done  86 tasks      | elapsed:    3.7s\n",
      "[Parallel(n_jobs=6)]: Done 101 tasks      | elapsed:    4.2s\n",
      "[Parallel(n_jobs=6)]: Done 116 tasks      | elapsed:    4.8s\n",
      "[Parallel(n_jobs=6)]: Done 133 tasks      | elapsed:    5.6s\n",
      "[Parallel(n_jobs=6)]: Done 150 tasks      | elapsed:    6.5s\n",
      "[Parallel(n_jobs=6)]: Done 169 tasks      | elapsed:    7.6s\n",
      "[Parallel(n_jobs=6)]: Done 188 tasks      | elapsed:    8.6s\n",
      "[Parallel(n_jobs=6)]: Done 209 tasks      | elapsed:    9.4s\n",
      "[Parallel(n_jobs=6)]: Done 230 tasks      | elapsed:   10.1s\n",
      "[Parallel(n_jobs=6)]: Done 253 tasks      | elapsed:   11.0s\n",
      "[Parallel(n_jobs=6)]: Done 276 tasks      | elapsed:   11.8s\n",
      "[Parallel(n_jobs=6)]: Done 301 tasks      | elapsed:   12.7s\n",
      "[Parallel(n_jobs=6)]: Done 326 tasks      | elapsed:   13.6s\n",
      "[Parallel(n_jobs=6)]: Done 353 tasks      | elapsed:   14.7s\n",
      "[Parallel(n_jobs=6)]: Done 380 tasks      | elapsed:   15.7s\n",
      "[Parallel(n_jobs=6)]: Done 409 tasks      | elapsed:   16.7s\n",
      "[Parallel(n_jobs=6)]: Done 438 tasks      | elapsed:   17.8s\n",
      "[Parallel(n_jobs=6)]: Done 469 tasks      | elapsed:   19.1s\n",
      "[Parallel(n_jobs=6)]: Done 500 tasks      | elapsed:   20.3s\n",
      "[Parallel(n_jobs=6)]: Done 533 tasks      | elapsed:   21.8s\n",
      "[Parallel(n_jobs=6)]: Done 566 tasks      | elapsed:   23.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best params\n",
      "{'max_leaf_nodes': 14, 'min_samples_leaf': 2}\n",
      "best score\n",
      "-6.728825706399575e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Done 585 out of 585 | elapsed:   24.0s finished\n"
     ]
    }
   ],
   "source": [
    "# {'max_depth': 4, 'min_samples_split': 4, 'n_estimators': 50} \n",
    "param_grid = {\n",
    "              \"min_samples_leaf\": range(1,10,1),\n",
    "              \"max_leaf_nodes\": range(2,15,1)\n",
    "              }\n",
    "    \n",
    "clf = RandomForestRegressor(\n",
    "            criterion ='mse', \n",
    "            n_estimators = 50,\n",
    "            max_depth = 4,\n",
    "            min_samples_split = 4,\n",
    "            random_state = 42\n",
    ")\n",
    "\n",
    "gsearch = GridSearchCV(estimator = clf, param_grid = param_grid, n_jobs=6,iid=False, verbose=10,scoring='neg_mean_squared_error')\n",
    "\n",
    "gsearch.fit(X_RAND_train,y_RAND_train)\n",
    "\n",
    "print('best params')\n",
    "print (gsearch.best_params_)\n",
    "print('best score')\n",
    "print (gsearch.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_rmse_ave: 0.008359151931886303\n",
      "[0.008046421179911343, 0.007522207654460264, 0.008970754200764595, 0.008192033878800358, 0.007261528804827015, 0.007389966886686526, 0.009434354784131698, 0.009095030814723662, 0.00923126977742949, 0.008447951337128053]\n",
      "\n",
      "\n",
      "test_r2_ave: 0.5800138319443187\n",
      "[0.6673317079609893, 0.6956681454215288, 0.4888757128331376, 0.5960708670050614, 0.6946648253743058, 0.6835371494626516, 0.40798747419915105, 0.5128303480153389, 0.46433192124209743, 0.5888401679289246]\n"
     ]
    }
   ],
   "source": [
    "rand_model = RandomForestRegressor( \n",
    "            criterion ='mse', \n",
    "            n_estimators = 50,\n",
    "            max_depth = 4,\n",
    "            min_samples_split = 4,\n",
    "            max_leaf_nodes = 14,\n",
    "            min_samples_leaf =2,\n",
    "            random_state = 42) \n",
    "rand_ave(skew_data[title], y,rand_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "clf = RandomForestRegressor(\n",
    "          criterion ='mse', \n",
    "          random_state = 42\n",
    ")\n",
    "X_RAND_train, X_RAND_test, y_RAND_train, y_RAND_test = train_test_split(skew_x, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 216 candidates, totalling 1080 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done   1 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=6)]: Done   6 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=6)]: Done  13 tasks      | elapsed:    1.5s\n",
      "[Parallel(n_jobs=6)]: Done  20 tasks      | elapsed:    2.0s\n",
      "[Parallel(n_jobs=6)]: Done  29 tasks      | elapsed:    3.2s\n",
      "[Parallel(n_jobs=6)]: Done  38 tasks      | elapsed:    4.1s\n",
      "[Parallel(n_jobs=6)]: Done  49 tasks      | elapsed:    6.1s\n",
      "[Parallel(n_jobs=6)]: Done  60 tasks      | elapsed:    8.5s\n",
      "[Parallel(n_jobs=6)]: Done  73 tasks      | elapsed:   10.5s\n",
      "[Parallel(n_jobs=6)]: Done  86 tasks      | elapsed:   13.8s\n",
      "[Parallel(n_jobs=6)]: Done 101 tasks      | elapsed:   16.9s\n",
      "[Parallel(n_jobs=6)]: Done 116 tasks      | elapsed:   19.6s\n",
      "[Parallel(n_jobs=6)]: Done 133 tasks      | elapsed:   23.1s\n",
      "[Parallel(n_jobs=6)]: Done 150 tasks      | elapsed:   26.6s\n",
      "[Parallel(n_jobs=6)]: Done 169 tasks      | elapsed:   30.7s\n",
      "[Parallel(n_jobs=6)]: Done 188 tasks      | elapsed:   33.2s\n",
      "[Parallel(n_jobs=6)]: Done 209 tasks      | elapsed:   36.2s\n",
      "[Parallel(n_jobs=6)]: Done 230 tasks      | elapsed:   39.1s\n",
      "[Parallel(n_jobs=6)]: Done 253 tasks      | elapsed:   43.0s\n",
      "[Parallel(n_jobs=6)]: Done 276 tasks      | elapsed:   46.7s\n",
      "[Parallel(n_jobs=6)]: Done 301 tasks      | elapsed:   50.9s\n",
      "[Parallel(n_jobs=6)]: Done 326 tasks      | elapsed:   55.8s\n",
      "[Parallel(n_jobs=6)]: Done 353 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=6)]: Done 380 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=6)]: Done 409 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=6)]: Done 438 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=6)]: Done 469 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=6)]: Done 500 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=6)]: Done 533 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=6)]: Done 566 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=6)]: Done 601 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=6)]: Done 636 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=6)]: Done 673 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=6)]: Done 710 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=6)]: Done 749 tasks      | elapsed:  2.7min\n",
      "[Parallel(n_jobs=6)]: Done 788 tasks      | elapsed:  2.9min\n",
      "[Parallel(n_jobs=6)]: Done 829 tasks      | elapsed:  3.1min\n",
      "[Parallel(n_jobs=6)]: Done 870 tasks      | elapsed:  3.3min\n",
      "[Parallel(n_jobs=6)]: Done 913 tasks      | elapsed:  3.6min\n",
      "[Parallel(n_jobs=6)]: Done 956 tasks      | elapsed:  3.8min\n",
      "[Parallel(n_jobs=6)]: Done 1001 tasks      | elapsed:  4.1min\n",
      "[Parallel(n_jobs=6)]: Done 1046 tasks      | elapsed:  4.4min\n",
      "[Parallel(n_jobs=6)]: Done 1080 out of 1080 | elapsed:  4.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best params\n",
      "{'max_depth': 8, 'min_samples_split': 5, 'n_estimators': 70}\n",
      "best score\n",
      "-2.2462212546004875e-06\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "#               'n_estimators': [50,100,200 ,500, 900],\n",
    "              'n_estimators': [70,90,120],\n",
    "              'max_depth': range(1,10,1),\n",
    "              'min_samples_split': range(2,10,1)}\n",
    "\n",
    "gsearch = GridSearchCV(estimator = clf, param_grid = param_grid, n_jobs=6,iid=False, verbose=10,scoring='neg_mean_squared_error')\n",
    "\n",
    "gsearch.fit(X_RAND_train,y_RAND_train)\n",
    "\n",
    "print('best params')\n",
    "print (gsearch.best_params_)\n",
    "print('best score')\n",
    "print (gsearch.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 117 candidates, totalling 585 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done   1 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=6)]: Done   6 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=6)]: Done  13 tasks      | elapsed:    1.9s\n",
      "[Parallel(n_jobs=6)]: Done  20 tasks      | elapsed:    2.5s\n",
      "[Parallel(n_jobs=6)]: Done  29 tasks      | elapsed:    3.3s\n",
      "[Parallel(n_jobs=6)]: Done  38 tasks      | elapsed:    4.4s\n",
      "[Parallel(n_jobs=6)]: Done  49 tasks      | elapsed:    5.9s\n",
      "[Parallel(n_jobs=6)]: Done  60 tasks      | elapsed:    7.5s\n",
      "[Parallel(n_jobs=6)]: Done  73 tasks      | elapsed:    9.3s\n",
      "[Parallel(n_jobs=6)]: Done  86 tasks      | elapsed:   10.8s\n",
      "[Parallel(n_jobs=6)]: Done 101 tasks      | elapsed:   12.7s\n",
      "[Parallel(n_jobs=6)]: Done 116 tasks      | elapsed:   14.6s\n",
      "[Parallel(n_jobs=6)]: Done 133 tasks      | elapsed:   17.0s\n",
      "[Parallel(n_jobs=6)]: Done 150 tasks      | elapsed:   19.4s\n",
      "[Parallel(n_jobs=6)]: Done 169 tasks      | elapsed:   23.5s\n",
      "[Parallel(n_jobs=6)]: Done 188 tasks      | elapsed:   26.7s\n",
      "[Parallel(n_jobs=6)]: Done 209 tasks      | elapsed:   30.0s\n",
      "[Parallel(n_jobs=6)]: Done 230 tasks      | elapsed:   35.2s\n",
      "[Parallel(n_jobs=6)]: Done 253 tasks      | elapsed:   41.8s\n",
      "[Parallel(n_jobs=6)]: Done 276 tasks      | elapsed:   46.0s\n",
      "[Parallel(n_jobs=6)]: Done 301 tasks      | elapsed:   50.2s\n",
      "[Parallel(n_jobs=6)]: Done 326 tasks      | elapsed:   54.3s\n",
      "[Parallel(n_jobs=6)]: Done 353 tasks      | elapsed:   59.0s\n",
      "[Parallel(n_jobs=6)]: Done 380 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=6)]: Done 409 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=6)]: Done 438 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=6)]: Done 469 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=6)]: Done 500 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=6)]: Done 533 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=6)]: Done 566 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=6)]: Done 585 out of 585 | elapsed:  1.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best params\n",
      "{'max_leaf_nodes': 6, 'min_samples_leaf': 3}\n",
      "best score\n",
      "-2.2442898710389254e-06\n"
     ]
    }
   ],
   "source": [
    "# {'max_depth': 4, 'min_samples_split': 4, 'n_estimators': 50} \n",
    "param_grid = {\n",
    "              \"min_samples_leaf\": range(1,10,1),\n",
    "              \"max_leaf_nodes\": range(2,15,1)\n",
    "              }\n",
    "    \n",
    "clf = RandomForestRegressor(\n",
    "            criterion ='mse', \n",
    "            n_estimators = 70,\n",
    "            max_depth = 8,\n",
    "            min_samples_split = 5,\n",
    "            random_state = 42\n",
    ")\n",
    "\n",
    "gsearch = GridSearchCV(estimator = clf, param_grid = param_grid, n_jobs=6,iid=False, verbose=10,scoring='neg_mean_squared_error')\n",
    "\n",
    "gsearch.fit(X_RAND_train,y_RAND_train)\n",
    "\n",
    "print('best params')\n",
    "print (gsearch.best_params_)\n",
    "print('best score')\n",
    "print (gsearch.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_rmse_ave: 0.001444905987628916\n",
      "[0.0012802474367970386, 0.0015333815383601196, 0.0014702092662872799, 0.00126021534464861, 0.00124194286497375, 0.0015728765667688894, 0.0014879040895896445, 0.0016264493132581046, 0.0013284243603350868, 0.0016474090952706363]\n",
      "\n",
      "\n",
      "test_r2_ave: 0.2446307298888894\n",
      "[0.2972907387186632, 0.3303203431353251, 0.3140268844095073, 0.05375738047783363, 0.2791045220039957, 0.12309683145078298, 0.32604951285374106, 0.18763141726441313, 0.28630857729075176, 0.24872109128387998]\n"
     ]
    }
   ],
   "source": [
    "rand_model = RandomForestRegressor( \n",
    "            criterion ='mse', \n",
    "            n_estimators = 70,\n",
    "            max_depth = 8,\n",
    "            min_samples_split = 5,\n",
    "            max_leaf_nodes = 6,\n",
    "            min_samples_leaf =3,\n",
    "            random_state = 42) \n",
    "rand_ave(skew_x, y,rand_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
