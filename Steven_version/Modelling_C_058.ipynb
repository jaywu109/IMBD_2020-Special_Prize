{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model 套件\n",
    "from sklearn.linear_model import LinearRegression, LassoCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "import math\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Second Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import MinMaxScaler, RobustScaler, StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 處理 data 套件\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let column can show all\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('BayesianRidge_Pre/Input_C_058.csv')\n",
    "# df1 = pd.read_csv('Input_C_057.csv')\n",
    "# df2 = pd.read_csv('Input_C_050.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = ['Input_C_054','Input_C_052','Input_C_055','Input_C_135']#'Input_C_056'#'Input_C_059','Input_C_060']\n",
    "\n",
    "# title = ['Input_C_054','Input_C_052','Input_C_055','Input_C_135','Input_C_056','Input_C_059','Input_C_060']\n",
    "\n",
    "\n",
    "#         ,'Input_A4_011','Input_A1_011','Input_A2_011','Input_C_053','Input_A3_011',\n",
    "#         'Input_A5_011','Input_A2_012','Input_A6_012','Input_C_051','Input_A1_012','Input_A5_012',\n",
    "#         'Input_A3_012','Input_A4_012']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[title]\n",
    "scaler = StandardScaler()\n",
    "df[title] = scaler.fit_transform(X)\n",
    "y = df['Predict']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 直接執行轉換拉到最下面會發現 Wraninig\n",
    "for col in title: # Predict 不做轉換\n",
    "    if abs(df[col].skew()) >= 0.7: # 取偏態絕對值大於 0.5的項\n",
    "        print(col)\n",
    "        pt = PowerTransformer() # PowerTransformer 預設為 Yeo-Johson 轉換可轉正負數，不同於另一種 Box-Cox 只能用於正數\n",
    "        d = pt.fit_transform(df[col].values.reshape(-1, 1)).flatten()\n",
    "        df[col]=d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pMSE(ans,predict):\n",
    "    pmse = math.sqrt(sum(pow((ans - predict)/ans*100,2)/len(ans)))\n",
    "    return pmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pNumber(ans,predict,num):\n",
    "    return sum(abs((ans-predict)/ans*100) < num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LassoCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso = LassoCV(alphas=[0.00001, 0.0001, 0.001, 0.01, 0.1, 1, 10, 20, 30],random_state = 42)\n",
    "lasso.fit(X_train, np.sqrt(y_train))\n",
    "alpha = lasso.alpha_\n",
    "print(\"first best alpha:\", alpha)\n",
    "lasso = LassoCV(alphas=[0.00004, 0.00008, 0.0001, 0.0003, 0.0006],random_state = 42)\n",
    "lasso.fit(X_train, np.sqrt(y_train))\n",
    "alpha = lasso.alpha_\n",
    "print(\"second best alpha:\", alpha)\n",
    "lasso = LassoCV(alphas=[0.0001 + i/100000 for i in range(1, 20)], random_state = 42)\n",
    "lasso.fit(X_train, np.sqrt(y_train))\n",
    "alpha = lasso.alpha_\n",
    "print(\"final best alpha:\", alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = lasso.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 預測值與實際值的差距，使用 r2_score ([0,1] 越大越好 )\n",
    "print(\"R2 score: %.4f\"\n",
    "      % r2_score(y_test, pow(y_pred,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Percentage mse score: %.2f\"\n",
    "      % pMSE(y_test,pow(y_pred,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number lower than error: %d\"\n",
    "      % pNumber(y_test, pow(y_pred,2), 15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 預測值與實際值的差距，使用 RMSE\n",
    "print(\"Root mean squared error: %.6f\"\n",
    "      % math.sqrt(mean_squared_error(y_test, pow(y_pred,2))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "abs((y_test - pow(y_pred,2))/y_test*100).describe(percentiles = p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lasso.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear regresssion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 建立一個線性回歸模型\n",
    "regr = LinearRegression()\n",
    "\n",
    "# 將訓練資料丟進去模型訓練\n",
    "regr.fit(X_train, y_train)\n",
    "\n",
    "# 將測試資料丟進模型得到預測結果\n",
    "y_pred = regr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 預測值與實際值的差距，使用 MSE\n",
    "print(\"Mean squared error: %.6f\"\n",
    "      % mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 預測值與實際值的差距，使用 RMSE\n",
    "print(\"Root mean squared error: %.6f\"\n",
    "      % math.sqrt(mean_squared_error(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 預測值與實際值的差距，使用 r2_score ([0,1] 越大越好 )\n",
    "print(\"R2 score: %.4f\"\n",
    "      % r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the score function displays the accuracy of the model which translates to how well the model \n",
    "# can accurately predict for a new datapoint.\n",
    "print(\"Linear regression score: %.4f\"\n",
    "      % regr.score(X_train,y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Percentage mse score: %.2f\"\n",
    "      % pMSE(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# y_test : len 103\n",
    "print(\"Number lower than error: %d\"   \n",
    "      % pNumber(y_test, y_pred, 15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "abs((y_test - y_pred)/y_test*100).describe(percentiles = p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sb\n",
    "%matplotlib inline\n",
    "sb.regplot(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# p-value: Used to interpret the test, in this case whether the sample was drawn from a Gaussian distribution.\n",
    "# If p-value <= alpha (0.05) : Reject H0 => need Normally distributed\n",
    "# If p-value > alpha (0.05) : Accept H0 \n",
    "from statsmodels.stats.diagnostic import normal_ad\n",
    "normal_ad(y_test - y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 對數化(平滑化)，將訓練資料丟進去模型訓練，看是要開根號或是取對數(這邊根號貌似較 better)\n",
    "regr.fit(X_train,np.sqrt(y_train))\n",
    "\n",
    "# 將測試資料丟進模型得到預測結果\n",
    "y_pred = regr.predict(X_test)\n",
    "\n",
    "# the score function displays the accuracy of the model which translates to how well the model \n",
    "# can accurately predict for a new datapoint.\n",
    "print(\"Linear regression score: %.4f\"\n",
    "      % regr.score(X_train,np.sqrt(y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sb.regplot(np.sqrt(y_test), y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "abs((y_test - pow(y_pred,2))/y_test*100).describe(percentiles = p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(\"Percentage mse score: %.2f\"\n",
    "      % pMSE(y_test, pow(y_pred,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number lower than error: %d\"\n",
    "      % pNumber(y_test, pow(y_pred,2), 15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 預測值與實際值的差距，使用 RMSE\n",
    "print(\"Root mean squared error: %.6f\"\n",
    "      % math.sqrt(mean_squared_error(y_test, pow(y_pred,2))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 預測值與實際值的差距，使用 r2_score ([0,1] 越大越好 )\n",
    "print(\"R2 score: %.4f\"\n",
    "      % r2_score(y_test,  pow(y_pred,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost.sklearn import XGBRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score,KFold\n",
    "from scipy.stats import skew\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 先調 booster / n_estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#for tuning parameters\n",
    "parameters_for_testing = {\n",
    "    'booster':['gbtree','gblinear','dart'],\n",
    "    'n_estimators':[50,60,70,80,90,100],\n",
    "}\n",
    "\n",
    "other_params = {'learning_rate': 0.1, 'n_estimators': 90, 'max_depth': 5, 'min_child_weight': 1, 'seed': 42,\n",
    "'subsample': 0.8, 'colsample_bytree': 0.8, 'gamma': 0, 'reg_alpha': 0, 'reg_lambda': 1}\n",
    "\n",
    "xgb_model = XGBRegressor(**other_params)\n",
    "gsearch = GridSearchCV(estimator = xgb_model, param_grid = parameters_for_testing, n_jobs=6,iid=False, verbose=10,scoring='r2')\n",
    "\n",
    "gsearch.fit(X_train,np.sqrt(y_train))\n",
    "\n",
    "#print (gsearch1.cv_results_)\n",
    "print('best params')\n",
    "print (gsearch.best_params_)\n",
    "print('best score')\n",
    "print (gsearch.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 調 max_depth / min_child_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#for tuning parameters\n",
    "parameters_for_testing = {\n",
    "    'max_depth': [1,2,3, 4, 5, 6, 7, 8, 9, 10], \n",
    "    'min_child_weight': [1, 2, 3, 4, 5, 6]\n",
    "}\n",
    "\n",
    "other_params = {'booster':'dart','learning_rate': 0.1, 'n_estimators': 60, 'seed': 42,\n",
    "'subsample': 0.8, 'colsample_bytree': 0.8, 'gamma': 0, 'reg_alpha': 0, 'reg_lambda': 1}\n",
    "\n",
    "xgb_model = XGBRegressor(**other_params)\n",
    "gsearch = GridSearchCV(estimator = xgb_model, param_grid = parameters_for_testing, n_jobs=6,iid=False, verbose=10,scoring='r2')\n",
    "\n",
    "gsearch.fit(X_train,np.sqrt(y_train))\n",
    "\n",
    "#print (gsearch1.cv_results_)\n",
    "print('best params')\n",
    "print (gsearch.best_params_)\n",
    "print('best score')\n",
    "print (gsearch.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 調 gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#for tuning parameters\n",
    "parameters_for_testing = {\n",
    "    'gamma': [0,0.1, 0.2, 0.3, 0.4, 0.5, 0.6]\n",
    "}\n",
    "\n",
    "other_params = {'booster':'dart','learning_rate': 0.1, 'n_estimators': 60, 'max_depth': 2, 'min_child_weight': 5, 'seed': 42,\n",
    "'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0, 'reg_lambda': 1}\n",
    "\n",
    "xgb_model = XGBRegressor(**other_params)\n",
    "gsearch = GridSearchCV(estimator = xgb_model, param_grid = parameters_for_testing, n_jobs=6,iid=False, verbose=10,scoring='r2')\n",
    "\n",
    "gsearch.fit(X_train,np.sqrt(y_train))\n",
    "\n",
    "#print (gsearch1.cv_results_)\n",
    "print('best params')\n",
    "print (gsearch.best_params_)\n",
    "print('best score')\n",
    "print (gsearch.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 調 subsample / colsample_bytree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#for tuning parameters\n",
    "parameters_for_testing = {\n",
    "    'subsample': [0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9], 'colsample_bytree': [0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "}\n",
    "\n",
    "other_params = {'booster':'dart','learning_rate': 0.1, 'n_estimators': 60, 'max_depth': 2, 'min_child_weight': 5, 'seed': 42,\n",
    " 'reg_alpha': 0, 'reg_lambda': 1, 'gamma':0}\n",
    "\n",
    "xgb_model = XGBRegressor(**other_params)\n",
    "gsearch = GridSearchCV(estimator = xgb_model, param_grid = parameters_for_testing, n_jobs=6,iid=False, verbose=10,scoring='r2')\n",
    "\n",
    "gsearch.fit(X_train,np.sqrt(y_train))\n",
    "\n",
    "#print (gsearch1.cv_results_)\n",
    "print('best params')\n",
    "print (gsearch.best_params_)\n",
    "print('best score')\n",
    "print (gsearch.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# reg_alpha / reg_lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#for tuning parameters\n",
    "parameters_for_testing = {\n",
    "    'reg_alpha': [0,0.05, 0.1, 0.5 , 1, 2, 3], 'reg_lambda': [0.05, 0.1, 0.5 , 1, 2, 3]\n",
    "}\n",
    "\n",
    "other_params = {'booster':'dart','learning_rate': 0.1, 'n_estimators': 60, 'max_depth': 2, 'min_child_weight': 5, 'seed': 42,\n",
    " 'gamma':0,'subsample':0.9,'colsample_bytree': 0.2}\n",
    "\n",
    "xgb_model = XGBRegressor(**other_params)\n",
    "gsearch = GridSearchCV(estimator = xgb_model, param_grid = parameters_for_testing, n_jobs=6,iid=False, verbose=10,scoring='r2')\n",
    "\n",
    "gsearch.fit(X_train,np.sqrt(y_train))\n",
    "\n",
    "#print (gsearch1.cv_results_)\n",
    "print('best params')\n",
    "print (gsearch.best_params_)\n",
    "print('best score')\n",
    "print (gsearch.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# learning_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for tuning parameters\n",
    "parameters_for_testing = {\n",
    "   'learning_rate': [0.01, 0.05, 0.07, 0.1, 0.2]\n",
    "}\n",
    "\n",
    "other_params = {'booster':'dart', 'n_estimators': 60, 'max_depth': 2, 'min_child_weight': 5, 'seed': 42,\n",
    " 'gamma':0,'subsample':0.9,'colsample_bytree': 0.2,'reg_alpha': 0, 'reg_lambda': 1}\n",
    "\n",
    "xgb_model = XGBRegressor(**other_params)\n",
    "gsearch = GridSearchCV(estimator = xgb_model, param_grid = parameters_for_testing, n_jobs=6,iid=False, verbose=10,scoring='r2')\n",
    "\n",
    "gsearch.fit(X_train,np.sqrt(y_train))\n",
    "\n",
    "#print (gsearch1.cv_results_)\n",
    "print('best params')\n",
    "print (gsearch.best_params_)\n",
    "print('best score')\n",
    "print (gsearch.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "best_xgb_model = XGBRegressor(\n",
    "              learning_rate = 0.1,\n",
    "              booster = 'dart', \n",
    "              n_estimators = 60, \n",
    "              max_depth = 2, \n",
    "              min_child_weight = 5,\n",
    "              seed = 42,\n",
    "              gamma = 0,\n",
    "              subsample = 0.9,\n",
    "              colsample_bytree = 0.2,\n",
    "              reg_alpha =  0,\n",
    "              reg_lambda = 1)\n",
    "\n",
    "best_xgb_model.fit(X_train,np.sqrt(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = best_xgb_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 預測值與實際值的差距，使用 r2_score ([0,1] 越大越好 )\n",
    "print(\"R2 score: %.4f\"\n",
    "      % r2_score(y_test, pow(y_pred,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Percentage rmse score: %.2f\"\n",
    "      % pMSE(y_test,pow(y_pred,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Number lower than error: %d\"\n",
    "      % pNumber(y_test, pow(y_pred,2), 15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 預測值與實際值的差距，使用 RMSE\n",
    "print(\"Root mean squared error: %.6f\"\n",
    "      % math.sqrt(mean_squared_error(y_test, pow(y_pred,2))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "abs((y_test - pow(y_pred,2))/y_test*100).describe(percentiles = p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the score function displays the accuracy of the model which translates to how well the model \n",
    "# can accurately predict for a new datapoint.\n",
    "print(\"XGBoost regression score: %.4f\"\n",
    "      % best_xgb_model.score(X_train,np.sqrt(y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# XGBoost\n",
    "xgb = XGBRegressor(booster = 'gblinear', loss = 'reg:linear')\n",
    "\n",
    "xgb.fit(X_train, np.sqrt(y_train))\n",
    "\n",
    "y_pred = xgb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = pd.concat([df[title], con1,con2], axis=1).to_numpy() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 預測值與實際值的差距，使用 r2_score ([0,1] 越大越好 )\n",
    "print(\"R2 score: %.4f\"\n",
    "      % r2_score(y_test, pow(y_pred,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Percentage rmse score: %.2f\"\n",
    "      % pMSE(y_test,pow(y_pred,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 預測值與實際值的差距，使用 RMSE\n",
    "print(\"Root mean squared error: %.6f\"\n",
    "      % math.sqrt(mean_squared_error(y_test, pow(y_pred,2))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
